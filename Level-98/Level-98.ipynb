{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-29T02:23:50.944795Z",
     "start_time": "2025-12-29T02:23:36.526362Z"
    }
   },
   "source": [
    "# level98_dynamic_var_fhs.py\n",
    "# Level-98: Dynamic VaR/ES with EWMA Volatility + Filtered Historical Simulation (FHS) + Backtesting\n",
    "#\n",
    "# Outputs:\n",
    "#   - level98_dynamic_var_series.csv\n",
    "#   - level98_dynamic_var_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level98_dynamic_var_fhs.py\n",
    "#   python level98_dynamic_var_fhs.py --method fhs --sims 20000 --window 756 --alpha 0.01\n",
    "#   python level98_dynamic_var_fhs.py --method ewma_normal --lambda 0.94\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    weights: Optional[Tuple[float, ...]] = None  # None -> equal-weight\n",
    "\n",
    "    alpha: float = 0.05\n",
    "    window: int = 756           # bootstrap window on standardized residuals\n",
    "    lam: float = 0.94           # EWMA lambda (RiskMetrics)\n",
    "\n",
    "    method: str = \"fhs\"         # \"fhs\" or \"ewma_normal\"\n",
    "    sims: int = 20000           # only used for FHS\n",
    "    use_log_returns: bool = True\n",
    "    dropna: bool = True\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level98_dynamic_var_series.csv\"\n",
    "    out_json: str = \"level98_dynamic_var_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _extract_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(f\"No data returned for {symbol}\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        # typical: columns like ('Close','SPY') etc.\n",
    "        for key in [(\"Adj Close\", symbol), (\"Close\", symbol), (symbol, \"Adj Close\"), (symbol, \"Close\")]:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                if isinstance(s, pd.DataFrame):\n",
    "                    s = s.iloc[:, 0]\n",
    "                s.name = symbol\n",
    "                return s\n",
    "        raise RuntimeError(f\"Could not extract Close/Adj Close for {symbol} from MultiIndex columns.\")\n",
    "\n",
    "    for col in [\"Adj Close\", \"Close\"]:\n",
    "        if col in px.columns:\n",
    "            s = px[col].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "    raise RuntimeError(f\"Missing Close/Adj Close for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    symbols = tuple(symbols)\n",
    "\n",
    "    # try batch download\n",
    "    try:\n",
    "        px_all = yf.download(list(symbols), start=start, progress=False, group_by=\"column\", auto_adjust=False)\n",
    "        if px_all is not None and not px_all.empty:\n",
    "            series = []\n",
    "            ok = True\n",
    "            for s in symbols:\n",
    "                try:\n",
    "                    series.append(_extract_close_series(px_all, s))\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok and series:\n",
    "                return pd.concat(series, axis=1).sort_index()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback single symbol\n",
    "    series = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, progress=False, auto_adjust=False)\n",
    "        series.append(_extract_close_series(px, s))\n",
    "    return pd.concat(series, axis=1).sort_index()\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame, use_log: bool) -> pd.DataFrame:\n",
    "    prices = prices.replace([np.inf, -np.inf], np.nan)\n",
    "    rets = (np.log(prices).diff() if use_log else prices.pct_change())\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan)\n",
    "    return rets.dropna(how=\"all\")\n",
    "\n",
    "\n",
    "def portfolio_weights(symbols: Tuple[str, ...], weights: Optional[Tuple[float, ...]]) -> np.ndarray:\n",
    "    n = len(symbols)\n",
    "    if weights is None:\n",
    "        return np.ones(n) / n\n",
    "    if len(weights) != n:\n",
    "        raise RuntimeError(f\"--weights length {len(weights)} must match symbols length {n}\")\n",
    "    w = np.array(weights, dtype=float)\n",
    "    s = float(w.sum())\n",
    "    if not np.isfinite(s) or s == 0.0:\n",
    "        raise RuntimeError(\"Weights sum is invalid/zero.\")\n",
    "    return w / s\n",
    "\n",
    "\n",
    "# ----------------------------- Math helpers (NO SciPy) -----------------------------\n",
    "def _safe_log(x: float) -> float:\n",
    "    return math.log(max(x, 1e-15))\n",
    "\n",
    "\n",
    "def inv_norm_cdf(p: float) -> float:\n",
    "    \"\"\"Approx inverse standard normal CDF (Acklam-like).\"\"\"\n",
    "    if p <= 0.0 or p >= 1.0:\n",
    "        raise ValueError(\"p must be in (0,1)\")\n",
    "\n",
    "    a = [-3.969683028665376e+01,  2.209460984245205e+02, -2.759285104469687e+02,\n",
    "          1.383577518672690e+02, -3.066479806614716e+01,  2.506628277459239e+00]\n",
    "    b = [-5.447609879822406e+01,  1.615858368580409e+02, -1.556989798598866e+02,\n",
    "          6.680131188771972e+01, -1.328068155288572e+01]\n",
    "    c = [-7.784894002430293e-03, -3.223964580411365e-01, -2.400758277161838e+00,\n",
    "         -2.549732539343734e+00,  4.374664141464968e+00,  2.938163982698783e+00]\n",
    "    d = [ 7.784695709041462e-03,  3.224671290700398e-01,  2.445134137142996e+00,\n",
    "          3.754408661907416e+00]\n",
    "\n",
    "    plow = 0.02425\n",
    "    phigh = 1 - plow\n",
    "\n",
    "    if p < plow:\n",
    "        q = math.sqrt(-2 * math.log(p))\n",
    "        num = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5])\n",
    "        den = ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
    "        return num / den\n",
    "    if p > phigh:\n",
    "        q = math.sqrt(-2 * math.log(1 - p))\n",
    "        num = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5])\n",
    "        den = ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
    "        return -(num / den)\n",
    "\n",
    "    q = p - 0.5\n",
    "    r = q * q\n",
    "    num = (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5]) * q\n",
    "    den = (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4]) * r + 1)\n",
    "    return num / den\n",
    "\n",
    "\n",
    "# ----------------------------- Backtests (NO SciPy) -----------------------------\n",
    "def kupiec_pof(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    T = int(exceed.size)\n",
    "    x = int(exceed.sum())\n",
    "    phat = x / T if T > 0 else 0.0\n",
    "\n",
    "    if x == 0:\n",
    "        lr = -2.0 * (T * _safe_log(1.0 - alpha))\n",
    "    elif x == T:\n",
    "        lr = -2.0 * (T * _safe_log(alpha))\n",
    "    else:\n",
    "        lnL0 = (T - x) * _safe_log(1.0 - alpha) + x * _safe_log(alpha)\n",
    "        lnL1 = (T - x) * _safe_log(1.0 - phat) + x * _safe_log(phat)\n",
    "        lr = -2.0 * (lnL0 - lnL1)\n",
    "\n",
    "    return {\"T\": float(T), \"x\": float(x), \"phat\": float(phat), \"LR_pof\": float(lr)}\n",
    "\n",
    "\n",
    "def christoffersen_ind(exceed: np.ndarray) -> Dict[str, float]:\n",
    "    e = exceed.astype(int)\n",
    "    if e.size < 2:\n",
    "        return {\"LR_ind\": float(\"nan\"), \"n00\": 0.0, \"n01\": 0.0, \"n10\": 0.0, \"n11\": 0.0}\n",
    "\n",
    "    e0, e1 = e[:-1], e[1:]\n",
    "    n00 = int(((e0 == 0) & (e1 == 0)).sum())\n",
    "    n01 = int(((e0 == 0) & (e1 == 1)).sum())\n",
    "    n10 = int(((e0 == 1) & (e1 == 0)).sum())\n",
    "    n11 = int(((e0 == 1) & (e1 == 1)).sum())\n",
    "\n",
    "    pi0 = n01 / (n00 + n01) if (n00 + n01) > 0 else 0.0\n",
    "    pi1 = n11 / (n10 + n11) if (n10 + n11) > 0 else 0.0\n",
    "    pi = (n01 + n11) / (n00 + n01 + n10 + n11) if (n00 + n01 + n10 + n11) > 0 else 0.0\n",
    "\n",
    "    lnL1 = n00 * _safe_log(1 - pi0) + n01 * _safe_log(pi0) + n10 * _safe_log(1 - pi1) + n11 * _safe_log(pi1)\n",
    "    lnL0 = (n00 + n10) * _safe_log(1 - pi) + (n01 + n11) * _safe_log(pi)\n",
    "    lr = -2.0 * (lnL0 - lnL1)\n",
    "\n",
    "    return {\n",
    "        \"LR_ind\": float(lr),\n",
    "        \"n00\": float(n00), \"n01\": float(n01), \"n10\": float(n10), \"n11\": float(n11),\n",
    "        \"pi\": float(pi), \"pi0\": float(pi0), \"pi1\": float(pi1)\n",
    "    }\n",
    "\n",
    "\n",
    "def christoffersen_cc(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    pof = kupiec_pof(exceed, alpha)\n",
    "    ind = christoffersen_ind(exceed)\n",
    "    lr_cc = float(pof[\"LR_pof\"] + ind[\"LR_ind\"]) if np.isfinite(ind[\"LR_ind\"]) else float(\"nan\")\n",
    "    return {\"LR_cc\": lr_cc, **{f\"pof_{k}\": v for k, v in pof.items()}, **{f\"ind_{k}\": v for k, v in ind.items()}}\n",
    "\n",
    "\n",
    "def es_tail_score(r: np.ndarray, var: np.ndarray, es: np.ndarray) -> Dict[str, float]:\n",
    "    mask = r <= var\n",
    "    n = int(mask.sum())\n",
    "    if n == 0:\n",
    "        return {\"n_tail\": 0.0, \"tail_mean_r\": float(\"nan\"), \"tail_mean_es\": float(\"nan\"), \"score\": float(\"nan\")}\n",
    "    tail_r = r[mask]\n",
    "    tail_es = es[mask]\n",
    "    return {\n",
    "        \"n_tail\": float(n),\n",
    "        \"tail_mean_r\": float(tail_r.mean()),\n",
    "        \"tail_mean_es\": float(tail_es.mean()),\n",
    "        \"score\": float((tail_r - tail_es).mean()),  # near 0 is good; negative => ES too optimistic\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- EWMA + Dynamic VaR -----------------------------\n",
    "def ewma_sigma(returns: np.ndarray, lam: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    EWMA volatility estimate:\n",
    "      sigma2_t = lam*sigma2_{t-1} + (1-lam)*r_{t-1}^2\n",
    "    We store sigma_t aligned with returns index (sigma[t] is sigma for time t).\n",
    "    \"\"\"\n",
    "    r = returns.astype(float)\n",
    "    n = r.size\n",
    "    sigma2 = np.full(n, np.nan, dtype=float)\n",
    "    # init variance using first 60 obs (or fewer if needed)\n",
    "    m = min(60, n)\n",
    "    v0 = float(np.var(r[:m], ddof=1)) if m >= 2 else float(np.var(r[:m]))\n",
    "    sigma2[0] = max(v0, 1e-12)\n",
    "\n",
    "    for t in range(1, n):\n",
    "        sigma2[t] = lam * sigma2[t - 1] + (1.0 - lam) * (r[t - 1] ** 2)\n",
    "\n",
    "    return np.sqrt(np.maximum(sigma2, 1e-12))\n",
    "\n",
    "\n",
    "def dynamic_var_es_ewma_normal(returns: np.ndarray, sigma: np.ndarray, alpha: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    z = inv_norm_cdf(alpha)  # negative\n",
    "    pdf = (1.0 / math.sqrt(2.0 * math.pi)) * math.exp(-0.5 * z * z)\n",
    "\n",
    "    var = sigma * z           # mean assumed 0 for daily returns\n",
    "    es = -sigma * (pdf / alpha)\n",
    "    return var, es\n",
    "\n",
    "\n",
    "def dynamic_var_es_fhs(returns: np.ndarray, sigma: np.ndarray, alpha: float, window: int, sims: int, seed: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Filtered Historical Simulation (FHS):\n",
    "      eps_t = r_t / sigma_t\n",
    "    For each t:\n",
    "      sample eps from last `window` eps values (bootstrap)\n",
    "      scenario returns = sigma_{t} * eps_sample   (or sigma_{t+1}; here sigma_t is next-day scale proxy)\n",
    "      VaR/ES from scenario distribution\n",
    "    \"\"\"\n",
    "    r = returns.astype(float)\n",
    "    eps = r / np.maximum(sigma, 1e-12)\n",
    "\n",
    "    n = r.size\n",
    "    var = np.full(n, np.nan, dtype=float)\n",
    "    es = np.full(n, np.nan, dtype=float)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    for t in range(window, n):\n",
    "        hist = eps[t - window:t]\n",
    "        # bootstrap indices vectorized\n",
    "        idx = rng.integers(0, window, size=sims)\n",
    "        scen = sigma[t] * hist[idx]  # dynamic scaling\n",
    "        q = float(np.quantile(scen, alpha))\n",
    "        var[t] = q\n",
    "        es[t] = float(scen[scen <= q].mean())\n",
    "\n",
    "    return var, es\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    method = cfg.method.lower().strip()\n",
    "    if method not in (\"fhs\", \"ewma_normal\"):\n",
    "        raise RuntimeError(\"--method must be 'fhs' or 'ewma_normal'\")\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices, cfg.use_log_returns)\n",
    "    if cfg.dropna:\n",
    "        rets = rets.dropna(how=\"any\")\n",
    "\n",
    "    if rets.empty:\n",
    "        raise RuntimeError(\"No returns after cleaning.\")\n",
    "\n",
    "    w = portfolio_weights(cfg.symbols, cfg.weights)\n",
    "    port = rets.values @ w\n",
    "    idx = rets.index\n",
    "\n",
    "    print(f\"[INFO] Data rows={len(rets)}, assets={rets.shape[1]}, method={method}, alpha={cfg.alpha}, lambda={cfg.lam}\")\n",
    "    sigma = ewma_sigma(port, cfg.lam)\n",
    "\n",
    "    if method == \"ewma_normal\":\n",
    "        var, es = dynamic_var_es_ewma_normal(port, sigma, cfg.alpha)\n",
    "    else:\n",
    "        if cfg.sims < 2000:\n",
    "            raise RuntimeError(\"--sims should be >= 2000 for stable FHS.\")\n",
    "        if len(port) <= cfg.window + 5:\n",
    "            raise RuntimeError(f\"Not enough rows for window={cfg.window}. rows={len(port)}\")\n",
    "        print(f\"[INFO] FHS bootstrap: window={cfg.window}, sims={cfg.sims} ...\")\n",
    "        var, es = dynamic_var_es_fhs(port, sigma, cfg.alpha, cfg.window, cfg.sims, cfg.seed)\n",
    "\n",
    "    valid = np.isfinite(var) & np.isfinite(es)\n",
    "    r_bt = port[valid]\n",
    "    var_bt = var[valid]\n",
    "    es_bt = es[valid]\n",
    "\n",
    "    exceed = (r_bt <= var_bt).astype(int)\n",
    "\n",
    "    pof = kupiec_pof(exceed, cfg.alpha)\n",
    "    ind = christoffersen_ind(exceed)\n",
    "    cc = christoffersen_cc(exceed, cfg.alpha)\n",
    "    es_score = es_tail_score(r_bt, var_bt, es_bt)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"date\": idx,\n",
    "        \"port_ret\": port,\n",
    "        \"sigma_ewma\": sigma,\n",
    "        \"VaR\": var,\n",
    "        \"ES\": es,\n",
    "    }).set_index(\"date\")\n",
    "    out[\"exceed\"] = ((out[\"port_ret\"] <= out[\"VaR\"]) & np.isfinite(out[\"VaR\"])).astype(int)\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(idx.min().date()),\n",
    "            \"end\": str(idx.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"n_backtest\": int(r_bt.size),\n",
    "        },\n",
    "        \"portfolio\": {\"symbols\": list(cfg.symbols), \"weights\": [float(x) for x in w]},\n",
    "        \"backtests\": {\n",
    "            \"kupiec_pof\": pof,\n",
    "            \"christoffersen_ind\": ind,\n",
    "            \"christoffersen_cc\": cc,\n",
    "            \"es_tail_score\": es_score,\n",
    "        },\n",
    "        \"notes\": [\n",
    "            \"EWMA makes VaR/ES time-varying; spikes during crises.\",\n",
    "            \"FHS preserves empirical non-normal residual shape while scaling by current volatility.\",\n",
    "            \"LR stats reported without p-values (no chi-square CDF without SciPy).\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return {\"series\": out, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    series: pd.DataFrame = result[\"series\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]        # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    series.to_csv(cfg.out_csv)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    bt = summary[\"backtests\"]\n",
    "    pof = bt[\"kupiec_pof\"]\n",
    "    ind = bt[\"christoffersen_ind\"]\n",
    "    cc = bt[\"christoffersen_cc\"]\n",
    "    esb = bt[\"es_tail_score\"]\n",
    "\n",
    "    print(f\"[OK] Saved series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(f\"[POF] T={int(pof['T'])} x={int(pof['x'])} phat={pof['phat']:.4f} LR={pof['LR_pof']:.3f}\")\n",
    "    print(f\"[IND] LR={ind['LR_ind']:.3f} n01={int(ind['n01'])} n11={int(ind['n11'])} pi0={ind['pi0']:.3f} pi1={ind['pi1']:.3f}\")\n",
    "    print(f\"[CC ] LR={cc['LR_cc']:.3f}\")\n",
    "    print(f\"[ES ] tail_n={int(esb['n_tail'])} score={esb['score']:.6f} (near 0 is good)\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-98: Dynamic VaR/ES via EWMA + (FHS or Normal) + Backtesting\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "    p.add_argument(\"--weights\", nargs=\"+\", type=float, default=None)\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--window\", type=int, default=Config.window)\n",
    "    p.add_argument(\"--lambda\", dest=\"lam\", type=float, default=Config.lam)\n",
    "\n",
    "    p.add_argument(\"--method\", type=str, default=Config.method, choices=[\"fhs\", \"ewma_normal\"])\n",
    "    p.add_argument(\"--sims\", type=int, default=Config.sims)\n",
    "\n",
    "    p.add_argument(\"--simple-returns\", action=\"store_true\")\n",
    "    p.add_argument(\"--no-dropna\", action=\"store_true\")\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    weights = tuple(a.weights) if a.weights is not None else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        weights=weights,\n",
    "        alpha=float(a.alpha),\n",
    "        window=int(a.window),\n",
    "        lam=float(a.lam),\n",
    "        method=str(a.method),\n",
    "        sims=int(a.sims),\n",
    "        use_log_returns=(not a.simple_returns),\n",
    "        dropna=(not a.no_dropna),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Data rows=4020, assets=8, method=fhs, alpha=0.05, lambda=0.94\n",
      "[INFO] FHS bootstrap: window=756, sims=20000 ...\n",
      "[OK] Saved series → level98_dynamic_var_series.csv\n",
      "[OK] Saved summary → level98_dynamic_var_summary.json\n",
      "[POF] T=3264 x=164 phat=0.0502 LR=0.004\n",
      "[IND] LR=0.935 n01=153 n11=11 pi0=0.049 pi1=0.067\n",
      "[CC ] LR=0.939\n",
      "[ES ] tail_n=164 score=0.000000 (near 0 is good)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

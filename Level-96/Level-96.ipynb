{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T19:15:25.375110Z",
     "start_time": "2025-12-28T19:15:22.097890Z"
    }
   },
   "source": [
    "# level96_mc_tcopula_var_es.py\n",
    "# Level-96: Monte Carlo VaR & ES using a fast t-like copula simulation (no SciPy, no np.erf)\n",
    "#\n",
    "# Outputs:\n",
    "#   - level96_mc_tcopula_var_es.csv\n",
    "#   - level96_mc_tcopula_var_es_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level96_mc_tcopula_var_es.py\n",
    "#   python level96_mc_tcopula_var_es.py --symbols SPY QQQ IWM TLT GLD --alpha 0.01 --n-sims 200000\n",
    "#   python level96_mc_tcopula_var_es.py --start 2015-01-01 --nu 8 --corr-shrink 0.15\n",
    "#   python level96_mc_tcopula_var_es.py --weights 0.4 0.25 0.15 0.15 0.05 --symbols SPY QQQ IWM TLT GLD\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    alpha: float = 0.05\n",
    "    n_sims: int = 200_000\n",
    "\n",
    "    # Dependence / tails\n",
    "    nu: int = 8                  # smaller => heavier tails; typical 6-12\n",
    "    corr_shrink: float = 0.10    # shrink correlation toward identity (0=no shrink)\n",
    "\n",
    "    # Portfolio weights\n",
    "    weights: Optional[Tuple[float, ...]] = None  # None -> equal weight\n",
    "\n",
    "    use_log_returns: bool = True\n",
    "    dropna: bool = True\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level96_mc_tcopula_var_es.csv\"\n",
    "    out_json: str = \"level96_mc_tcopula_var_es_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _extract_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(f\"No data returned for {symbol}\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        candidates = [\n",
    "            (\"Adj Close\", symbol),\n",
    "            (\"Close\", symbol),\n",
    "            (symbol, \"Adj Close\"),\n",
    "            (symbol, \"Close\"),\n",
    "        ]\n",
    "        for key in candidates:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                if isinstance(s, pd.DataFrame):\n",
    "                    s = s.iloc[:, 0]\n",
    "                s.name = symbol\n",
    "                return s\n",
    "\n",
    "        raise RuntimeError(f\"Could not extract Close/Adj Close for {symbol} from MultiIndex columns.\")\n",
    "\n",
    "    for col in [\"Adj Close\", \"Close\"]:\n",
    "        if col in px.columns:\n",
    "            s = px[col].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "    raise RuntimeError(f\"Missing Close/Adj Close for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    symbols = tuple(symbols)\n",
    "\n",
    "    # Batch attempt first\n",
    "    try:\n",
    "        px_all = yf.download(list(symbols), start=start, progress=False, group_by=\"column\", auto_adjust=False)\n",
    "        if px_all is not None and not px_all.empty:\n",
    "            ss = []\n",
    "            ok = True\n",
    "            for s in symbols:\n",
    "                try:\n",
    "                    ss.append(_extract_close_series(px_all, s))\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok and ss:\n",
    "                return pd.concat(ss, axis=1).sort_index()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback single-symbol\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, progress=False, auto_adjust=False)\n",
    "        frames.append(_extract_close_series(px, s))\n",
    "    return pd.concat(frames, axis=1).sort_index()\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame, use_log: bool) -> pd.DataFrame:\n",
    "    prices = prices.replace([np.inf, -np.inf], np.nan)\n",
    "    if use_log:\n",
    "        rets = np.log(prices).diff()\n",
    "    else:\n",
    "        rets = prices.pct_change()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan)\n",
    "    rets = rets.dropna(how=\"all\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- Math helpers -----------------------------\n",
    "def shrink_corr(corr: np.ndarray, shrink: float) -> np.ndarray:\n",
    "    n = corr.shape[0]\n",
    "    I = np.eye(n)\n",
    "    out = (1.0 - shrink) * corr + shrink * I\n",
    "    out = 0.5 * (out + out.T)\n",
    "    return out\n",
    "\n",
    "\n",
    "def nearest_psd_corr(A: np.ndarray, eps: float = 1e-10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make correlation PSD by eigenvalue clipping and re-normalization.\n",
    "    \"\"\"\n",
    "    A = 0.5 * (A + A.T)\n",
    "    w, v = np.linalg.eigh(A)\n",
    "    w = np.maximum(w, eps)\n",
    "    B = (v * w) @ v.T\n",
    "    B = 0.5 * (B + B.T)\n",
    "    d = np.sqrt(np.diag(B))\n",
    "    B = B / np.outer(d, d)\n",
    "    B = np.clip(B, -1.0, 1.0)\n",
    "    np.fill_diagonal(B, 1.0)\n",
    "    return B\n",
    "\n",
    "\n",
    "def portfolio_weights(symbols: Tuple[str, ...], weights: Optional[Tuple[float, ...]]) -> np.ndarray:\n",
    "    n = len(symbols)\n",
    "    if weights is None:\n",
    "        return np.ones(n) / n\n",
    "    if len(weights) != n:\n",
    "        raise RuntimeError(f\"--weights length {len(weights)} must match symbols length {n}\")\n",
    "    w = np.array(weights, dtype=float)\n",
    "    s = float(w.sum())\n",
    "    if s == 0 or not np.isfinite(s):\n",
    "        raise RuntimeError(\"Weights sum to 0 or invalid.\")\n",
    "    return w / s\n",
    "\n",
    "\n",
    "def empirical_ppf(samples_sorted: np.ndarray, u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Fast empirical inverse CDF using sorted samples and linear interpolation.\n",
    "    \"\"\"\n",
    "    T = samples_sorted.size\n",
    "    idx = u * (T - 1)\n",
    "    lo = np.floor(idx).astype(int)\n",
    "    hi = np.minimum(lo + 1, T - 1)\n",
    "    w = idx - lo\n",
    "    return (1.0 - w) * samples_sorted[lo] + w * samples_sorted[hi]\n",
    "\n",
    "\n",
    "def norm_cdf_approx(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized Normal CDF approximation (no erf, no scipy).\n",
    "    Abramowitz-Stegun style approximation for Phi(x).\n",
    "\n",
    "    Accuracy is more than sufficient for copula-uniform mapping.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    sign = np.where(x >= 0.0, 1.0, -1.0)\n",
    "    ax = np.abs(x) / math.sqrt(2.0)\n",
    "\n",
    "    # approximation for erf(ax):\n",
    "    # erf(z) ~ 1 - (((((a5*t + a4)*t + a3)*t + a2)*t + a1)*t)*exp(-z^2)\n",
    "    t = 1.0 / (1.0 + 0.3275911 * ax)\n",
    "    a1 = 0.254829592\n",
    "    a2 = -0.284496736\n",
    "    a3 = 1.421413741\n",
    "    a4 = -1.453152027\n",
    "    a5 = 1.061405429\n",
    "\n",
    "    poly = (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t)\n",
    "    erf_approx = 1.0 - poly * np.exp(-ax * ax)\n",
    "    erf_approx = sign * erf_approx\n",
    "\n",
    "    # Phi(x) = 0.5*(1 + erf(x/sqrt(2)))\n",
    "    return 0.5 * (1.0 + erf_approx)\n",
    "\n",
    "\n",
    "# ----------------------------- Main pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices, cfg.use_log_returns)\n",
    "    if cfg.dropna:\n",
    "        rets = rets.dropna(how=\"any\")\n",
    "\n",
    "    if rets.empty or len(rets) < 500:\n",
    "        raise RuntimeError(f\"Not enough return history after cleaning. rows={len(rets)}\")\n",
    "\n",
    "    n_assets = rets.shape[1]\n",
    "    w = portfolio_weights(cfg.symbols, cfg.weights)\n",
    "\n",
    "    print(f\"[INFO] Data rows={len(rets)}, assets={n_assets}, sims={cfg.n_sims}, nu={cfg.nu}\")\n",
    "\n",
    "    # correlation\n",
    "    corr = np.corrcoef(rets.values, rowvar=False)\n",
    "    corr = shrink_corr(corr, cfg.corr_shrink)\n",
    "    corr = nearest_psd_corr(corr)\n",
    "\n",
    "    # cholesky\n",
    "    L = np.linalg.cholesky(corr)\n",
    "\n",
    "    # --- Simulate heavy-tailed correlated drivers ---\n",
    "    Z = np.random.randn(cfg.n_sims, n_assets) @ L.T\n",
    "\n",
    "    # Student-t scale mixing\n",
    "    S = np.random.chisquare(df=cfg.nu, size=cfg.n_sims)\n",
    "    scale = np.sqrt(cfg.nu / S).reshape(-1, 1)\n",
    "    X = Z * scale\n",
    "\n",
    "    # Convert to uniforms using normal cdf approximation (fast, vectorized)\n",
    "    U = norm_cdf_approx(X)\n",
    "    U = np.clip(U, 1e-6, 1.0 - 1e-6)\n",
    "\n",
    "    # Map to empirical return distribution\n",
    "    sim_rets = np.zeros_like(U)\n",
    "    for j, sym in enumerate(cfg.symbols):\n",
    "        samp = np.sort(rets[sym].values.astype(float))\n",
    "        sim_rets[:, j] = empirical_ppf(samp, U[:, j])\n",
    "\n",
    "    port_sim = sim_rets @ w\n",
    "\n",
    "    # VaR / ES\n",
    "    var_mc = float(np.quantile(port_sim, cfg.alpha))\n",
    "    es_mc = float(port_sim[port_sim <= var_mc].mean())\n",
    "\n",
    "    # Historical comparison\n",
    "    ph = rets.values @ w\n",
    "    var_hist = float(np.quantile(ph, cfg.alpha))\n",
    "    es_hist = float(ph[ph <= var_hist].mean())\n",
    "\n",
    "    out = pd.DataFrame({\"port_sim\": port_sim})\n",
    "    out[\"is_tail\"] = (out[\"port_sim\"] <= var_mc).astype(int)\n",
    "\n",
    "    ann_vol_hist = float(np.std(ph, ddof=1) * math.sqrt(252.0))\n",
    "    ann_ret_hist = float(np.mean(ph) * 252.0)\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"assets\": int(n_assets),\n",
    "        },\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": list(cfg.symbols),\n",
    "            \"weights\": [float(x) for x in w],\n",
    "            \"hist_ann_ret\": ann_ret_hist,\n",
    "            \"hist_ann_vol\": ann_vol_hist,\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"alpha\": float(cfg.alpha),\n",
    "            \"mc_var\": var_mc,\n",
    "            \"mc_es\": es_mc,\n",
    "            \"hist_var\": var_hist,\n",
    "            \"hist_es\": es_hist,\n",
    "        },\n",
    "        \"notes\": [\n",
    "            \"No scipy. No erf. Normal-CDF uses a vectorized approximation.\",\n",
    "            \"Dependence from return correlation; heavy tails via Student-t scale mixing (nu).\",\n",
    "            \"Uniforms are mapped to each asset’s empirical return distribution via fast empirical PPF.\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return {\"sim\": out, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    df: pd.DataFrame = result[\"sim\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]  # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    df.to_csv(cfg.out_csv, index=False)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    r = summary[\"results\"]\n",
    "    print(f\"[OK] Saved sims → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(\n",
    "        f\"[RESULT] alpha={r['alpha']:.3f}  \"\n",
    "        f\"MC VaR={r['mc_var']:.6f}  MC ES={r['mc_es']:.6f}  \"\n",
    "        f\"Hist VaR={r['hist_var']:.6f}  Hist ES={r['hist_es']:.6f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-96: Monte Carlo VaR/ES using fast t-like copula simulation\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--n-sims\", type=int, default=Config.n_sims)\n",
    "\n",
    "    p.add_argument(\"--nu\", type=int, default=Config.nu)\n",
    "    p.add_argument(\"--corr-shrink\", type=float, default=Config.corr_shrink)\n",
    "\n",
    "    p.add_argument(\"--weights\", nargs=\"+\", type=float, default=None)\n",
    "\n",
    "    p.add_argument(\"--simple-returns\", action=\"store_true\")\n",
    "    p.add_argument(\"--no-dropna\", action=\"store_true\")\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    weights = tuple(a.weights) if a.weights is not None else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        alpha=float(a.alpha),\n",
    "        n_sims=int(a.n_sims),\n",
    "        nu=int(a.nu),\n",
    "        corr_shrink=float(a.corr_shrink),\n",
    "        weights=weights,\n",
    "        use_log_returns=(not a.simple_returns),\n",
    "        dropna=(not a.no_dropna),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Data rows=4020, assets=8, sims=200000, nu=8\n",
      "[OK] Saved sims → level96_mc_tcopula_var_es.csv\n",
      "[OK] Saved summary → level96_mc_tcopula_var_es_summary.json\n",
      "[RESULT] alpha=0.050  MC VaR=-0.014416  MC ES=-0.025982  Hist VaR=-0.011308  Hist ES=-0.017759\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

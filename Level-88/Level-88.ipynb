{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T16:59:06.401546Z",
     "start_time": "2025-12-27T16:59:05.436101Z"
    }
   },
   "source": [
    "# level88_granger_network.py\n",
    "# Level-88: Granger-Causality Network + Influence Ranking (free-data)\n",
    "#\n",
    "# Outputs:\n",
    "#   - level88_gc_pvalues.csv\n",
    "#   - level88_gc_adjacency.csv\n",
    "#   - level88_gc_centrality.csv\n",
    "#   - level88_gc_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level88_granger_network.py\n",
    "#   python level88_granger_network.py --symbols SPY QQQ IWM EFA EEM TLT LQD GLD --start 2010-01-01\n",
    "#   python level88_granger_network.py --p 2 --alpha 0.05\n",
    "#   python level88_granger_network.py --rolling --window 756 --step 21   (optional, slower)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    p: int = 2                  # VAR lags\n",
    "    alpha: float = 0.05         # significance threshold for edges\n",
    "    min_obs: int = 800\n",
    "\n",
    "    rolling: bool = False\n",
    "    window: int = 756           # ~3y\n",
    "    step: int = 21              # monthly\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "    out_pvals_csv: str = \"level88_gc_pvalues.csv\"\n",
    "    out_adj_csv: str = \"level88_gc_adjacency.csv\"\n",
    "    out_cent_csv: str = \"level88_gc_centrality.csv\"\n",
    "    out_json: str = \"level88_gc_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- yfinance loader -----------------------------\n",
    "def _safe_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        for key in [(\"Close\", symbol), (\"Adj Close\", symbol), (symbol, \"Close\"), (symbol, \"Adj Close\")]:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                s.name = symbol\n",
    "                return s\n",
    "        candidates = [\n",
    "            c for c in px.columns\n",
    "            if isinstance(c, tuple) and (symbol in c) and (\"Close\" in c or \"Adj Close\" in c)\n",
    "        ]\n",
    "        if candidates:\n",
    "            s = px[candidates[0]].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        raise RuntimeError(f\"Could not locate Close/Adj Close for {symbol} in MultiIndex columns.\")\n",
    "\n",
    "    if \"Close\" in px.columns:\n",
    "        s = px[\"Close\"].copy()\n",
    "        s.name = symbol\n",
    "        return s\n",
    "    if \"Adj Close\" in px.columns:\n",
    "        s = px[\"Adj Close\"].copy()\n",
    "        s.name = symbol\n",
    "        return s\n",
    "    raise RuntimeError(f\"'Close' missing for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    px = yf.download(\n",
    "        list(symbols),\n",
    "        start=start,\n",
    "        auto_adjust=True,\n",
    "        progress=False,\n",
    "        group_by=\"column\",\n",
    "        threads=True,\n",
    "    )\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(\"No price data returned from yfinance.\")\n",
    "    frames = [_safe_close_series(px, s) for s in symbols]\n",
    "    prices = pd.concat(frames, axis=1).sort_index().dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    rets = np.log(prices).diff().dropna()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- Centrality (no external deps) -----------------------------\n",
    "def pagerank_from_adjacency(adj: np.ndarray, damping: float = 0.85, iters: int = 200, tol: float = 1e-10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Directed PageRank on adjacency matrix (i -> j) edges.\n",
    "    We build transition matrix where outgoing edges distribute probability.\n",
    "    \"\"\"\n",
    "    n = adj.shape[0]\n",
    "    M = adj.astype(float).copy()\n",
    "    out = M.sum(axis=1)\n",
    "    # Handle dangling nodes\n",
    "    for i in range(n):\n",
    "        if out[i] > 0:\n",
    "            M[i, :] /= out[i]\n",
    "        else:\n",
    "            M[i, :] = 1.0 / n\n",
    "\n",
    "    r = np.ones(n) / n\n",
    "    teleport = np.ones(n) / n\n",
    "\n",
    "    for _ in range(iters):\n",
    "        r_new = damping * (M.T @ r) + (1.0 - damping) * teleport\n",
    "        if np.max(np.abs(r_new - r)) < tol:\n",
    "            r = r_new\n",
    "            break\n",
    "        r = r_new\n",
    "    return r\n",
    "\n",
    "\n",
    "# ----------------------------- Pairwise GC matrix -----------------------------\n",
    "def granger_matrix(rets: pd.DataFrame, p: int) -> pd.DataFrame:\n",
    "    if len(rets) < 10 * p:\n",
    "        raise RuntimeError(\"Too few observations for VAR / Granger tests.\")\n",
    "    model = VAR(rets)\n",
    "    res = model.fit(p)\n",
    "\n",
    "    syms = list(rets.columns)\n",
    "    n = len(syms)\n",
    "    pvals = np.ones((n, n), dtype=float)\n",
    "\n",
    "    # pvals[i,j] = p-value for i -> j (i causes j)\n",
    "    for i, src in enumerate(syms):\n",
    "        for j, tgt in enumerate(syms):\n",
    "            if i == j:\n",
    "                pvals[i, j] = np.nan\n",
    "                continue\n",
    "            try:\n",
    "                test = res.test_causality(caused=tgt, causing=[src], kind=\"f\")\n",
    "                pvals[i, j] = float(test.pvalue)\n",
    "            except Exception:\n",
    "                pvals[i, j] = np.nan\n",
    "\n",
    "    return pd.DataFrame(pvals, index=syms, columns=syms)\n",
    "\n",
    "\n",
    "def compute_centrality(pvals: pd.DataFrame, alpha: float) -> Dict[str, pd.DataFrame]:\n",
    "    syms = list(pvals.index)\n",
    "    n = len(syms)\n",
    "\n",
    "    adj = (pvals.values < alpha).astype(int)\n",
    "    np.fill_diagonal(adj, 0)\n",
    "\n",
    "    out_deg = adj.sum(axis=1)\n",
    "    in_deg = adj.sum(axis=0)\n",
    "    net = out_deg - in_deg\n",
    "    pr = pagerank_from_adjacency(adj)\n",
    "\n",
    "    cent = pd.DataFrame({\n",
    "        \"out_degree\": out_deg,\n",
    "        \"in_degree\": in_deg,\n",
    "        \"net_influence\": net,\n",
    "        \"pagerank\": pr\n",
    "    }, index=syms).sort_values([\"net_influence\", \"pagerank\"], ascending=[False, False])\n",
    "\n",
    "    return {\n",
    "        \"adjacency\": pd.DataFrame(adj, index=syms, columns=syms),\n",
    "        \"centrality\": cent\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Rolling total influence (optional) -----------------------------\n",
    "def rolling_net_influence(rets: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    idx = rets.index\n",
    "    syms = list(rets.columns)\n",
    "\n",
    "    dates = []\n",
    "    rows = []\n",
    "\n",
    "    for start_i in range(0, len(rets) - cfg.window + 1, cfg.step):\n",
    "        end_i = start_i + cfg.window\n",
    "        sub = rets.iloc[start_i:end_i]\n",
    "        pvals = granger_matrix(sub, cfg.p)\n",
    "        adj = (pvals.values < cfg.alpha).astype(int)\n",
    "        np.fill_diagonal(adj, 0)\n",
    "        out_deg = adj.sum(axis=1)\n",
    "        in_deg = adj.sum(axis=0)\n",
    "        net = out_deg - in_deg\n",
    "\n",
    "        dates.append(idx[end_i - 1])\n",
    "        rows.append(net.astype(float))\n",
    "\n",
    "    return pd.DataFrame(rows, index=pd.DatetimeIndex(dates), columns=syms)\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_log_returns(prices)\n",
    "\n",
    "    if len(rets) < cfg.min_obs:\n",
    "        raise RuntimeError(f\"Not enough observations: {len(rets)} < min_obs={cfg.min_obs}\")\n",
    "\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, assets={rets.shape[1]}\")\n",
    "\n",
    "    pvals = granger_matrix(rets, cfg.p)\n",
    "    out = compute_centrality(pvals, cfg.alpha)\n",
    "\n",
    "    roll = None\n",
    "    if cfg.rolling:\n",
    "        print(f\"[INFO] Rolling influence: window={cfg.window}, step={cfg.step} ...\")\n",
    "        roll = rolling_net_influence(rets, cfg)\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"assets\": int(rets.shape[1]),\n",
    "        },\n",
    "        \"var\": {\"lags\": int(cfg.p)},\n",
    "        \"alpha_edge_threshold\": float(cfg.alpha),\n",
    "        \"top_emitters_by_net_influence\": out[\"centrality\"].head(10).index.tolist(),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"returns\": rets,\n",
    "        \"pvalues\": pvals,\n",
    "        \"adjacency\": out[\"adjacency\"],\n",
    "        \"centrality\": out[\"centrality\"],\n",
    "        \"rolling_net\": roll,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    pvals: pd.DataFrame = result[\"pvalues\"]  # type: ignore\n",
    "    adj: pd.DataFrame = result[\"adjacency\"]  # type: ignore\n",
    "    cent: pd.DataFrame = result[\"centrality\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]  # type: ignore\n",
    "    roll = result.get(\"rolling_net\", None)\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_pvals_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_adj_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_cent_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    pvals.to_csv(cfg.out_pvals_csv)\n",
    "    adj.to_csv(cfg.out_adj_csv)\n",
    "    cent.to_csv(cfg.out_cent_csv)\n",
    "\n",
    "    if roll is not None:\n",
    "        roll_path = cfg.out_cent_csv.replace(\".csv\", \"_rolling_net.csv\")\n",
    "        roll.to_csv(roll_path)\n",
    "        summary[\"rolling_net_csv\"] = roll_path\n",
    "        print(f\"[OK] Saved rolling net influence → {roll_path}\")\n",
    "\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved p-values   → {cfg.out_pvals_csv}\")\n",
    "    print(f\"[OK] Saved adjacency  → {cfg.out_adj_csv}\")\n",
    "    print(f\"[OK] Saved centrality → {cfg.out_cent_csv}\")\n",
    "    print(f\"[OK] Saved summary    → {cfg.out_json}\")\n",
    "\n",
    "    print(\"[TOP] Net influence (out - in) & PageRank:\")\n",
    "    top = cent.head(min(10, len(cent)))\n",
    "    for sym, r in top.iterrows():\n",
    "        print(\n",
    "            f\"  {sym:>5s}  net={int(r['net_influence']):>3d}  \"\n",
    "            f\"out={int(r['out_degree']):>3d}  in={int(r['in_degree']):>3d}  \"\n",
    "            f\"pagerank={r['pagerank']:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-88: Granger-Causality Network + Influence Ranking\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--p\", type=int, default=2)\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.05)\n",
    "    p.add_argument(\"--min-obs\", type=int, default=800)\n",
    "\n",
    "    p.add_argument(\"--rolling\", action=\"store_true\")\n",
    "    p.add_argument(\"--window\", type=int, default=756)\n",
    "    p.add_argument(\"--step\", type=int, default=21)\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    p.add_argument(\"--pvals-csv\", type=str, default=\"level88_gc_pvalues.csv\")\n",
    "    p.add_argument(\"--adj-csv\", type=str, default=\"level88_gc_adjacency.csv\")\n",
    "    p.add_argument(\"--cent-csv\", type=str, default=\"level88_gc_centrality.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level88_gc_summary.json\")\n",
    "\n",
    "    a = p.parse_args()\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        p=int(a.p),\n",
    "        alpha=float(a.alpha),\n",
    "        min_obs=int(a.min_obs),\n",
    "        rolling=bool(a.rolling),\n",
    "        window=int(a.window),\n",
    "        step=int(a.step),\n",
    "        seed=int(a.seed),\n",
    "        out_pvals_csv=a.pvals_csv,\n",
    "        out_adj_csv=a.adj_csv,\n",
    "        out_cent_csv=a.cent_csv,\n",
    "        out_json=a.json\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4021 price rows, 4020 return rows, assets=8\n",
      "[OK] Saved p-values   → level88_gc_pvalues.csv\n",
      "[OK] Saved adjacency  → level88_gc_adjacency.csv\n",
      "[OK] Saved centrality → level88_gc_centrality.csv\n",
      "[OK] Saved summary    → level88_gc_summary.json\n",
      "[TOP] Net influence (out - in) & PageRank:\n",
      "    LQD  net=  5  out=  7  in=  2  pagerank=0.1846\n",
      "    TLT  net=  3  out=  4  in=  1  pagerank=0.0826\n",
      "    SPY  net=  2  out=  4  in=  2  pagerank=0.1001\n",
      "    GLD  net= -2  out=  0  in=  2  pagerank=0.1858\n",
      "    IWM  net= -2  out=  1  in=  3  pagerank=0.1214\n",
      "    EEM  net= -2  out=  1  in=  3  pagerank=0.1214\n",
      "    QQQ  net= -2  out=  0  in=  2  pagerank=0.1039\n",
      "    EFA  net= -2  out=  0  in=  2  pagerank=0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

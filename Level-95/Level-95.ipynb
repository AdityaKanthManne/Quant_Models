{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T19:02:04.129670Z",
     "start_time": "2025-12-28T19:02:02.653970Z"
    }
   },
   "source": [
    "# level95_var_es_backtest.py\n",
    "# Level-95: VaR + ES Backtesting (Kupiec + Christoffersen) on a Portfolio (free-data)\n",
    "#\n",
    "# Computes rolling Historical VaR/ES and evaluates:\n",
    "#  - Kupiec POF (unconditional coverage)\n",
    "#  - Christoffersen independence test\n",
    "#  - Christoffersen conditional coverage test\n",
    "#\n",
    "# Outputs:\n",
    "#   - level95_var_es_series.csv\n",
    "#   - level95_var_es_backtest_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level95_var_es_backtest.py\n",
    "#   python level95_var_es_backtest.py --symbols SPY QQQ IWM --alpha 0.01 --window 750\n",
    "#   python level95_var_es_backtest.py --weights 0.5 0.3 0.2 --symbols SPY QQQ TLT\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    alpha: float = 0.05          # tail probability (e.g., 0.01 or 0.05)\n",
    "    window: int = 756            # rolling window for historical VaR/ES (~3y trading days)\n",
    "\n",
    "    use_log_returns: bool = True\n",
    "    dropna: bool = True\n",
    "\n",
    "    # portfolio\n",
    "    weights: Optional[Tuple[float, ...]] = None  # if None -> equal weight\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level95_var_es_series.csv\"\n",
    "    out_json: str = \"level95_var_es_backtest_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _extract_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(f\"No data returned for {symbol}\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        candidates = [\n",
    "            (\"Adj Close\", symbol),\n",
    "            (\"Close\", symbol),\n",
    "            (symbol, \"Adj Close\"),\n",
    "            (symbol, \"Close\"),\n",
    "        ]\n",
    "        for key in candidates:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                if isinstance(s, pd.DataFrame):\n",
    "                    s = s.iloc[:, 0]\n",
    "                s.name = symbol\n",
    "                return s\n",
    "\n",
    "        # fallback scan\n",
    "        cols = []\n",
    "        for c in px.columns:\n",
    "            c0 = str(c[0]).lower()\n",
    "            c1 = str(c[1]).lower()\n",
    "            if (symbol.lower() in c0 or symbol.lower() in c1) and (\"close\" in c0):\n",
    "                cols.append(c)\n",
    "        if cols:\n",
    "            s = px[cols[0]].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "        raise RuntimeError(f\"Could not extract Close/Adj Close for {symbol} from MultiIndex columns.\")\n",
    "\n",
    "    for col in [\"Adj Close\", \"Close\"]:\n",
    "        if col in px.columns:\n",
    "            s = px[col].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "    raise RuntimeError(f\"Missing Close/Adj Close for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    symbols = tuple(symbols)\n",
    "\n",
    "    # try batch download first\n",
    "    try:\n",
    "        px_all = yf.download(list(symbols), start=start, progress=False, group_by=\"column\", auto_adjust=False)\n",
    "        if px_all is not None and not px_all.empty:\n",
    "            ss = []\n",
    "            ok = True\n",
    "            for s in symbols:\n",
    "                try:\n",
    "                    ss.append(_extract_close_series(px_all, s))\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok and ss:\n",
    "                return pd.concat(ss, axis=1).sort_index()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback per symbol\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, progress=False, auto_adjust=False)\n",
    "        frames.append(_extract_close_series(px, s))\n",
    "    return pd.concat(frames, axis=1).sort_index()\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame, use_log: bool) -> pd.DataFrame:\n",
    "    prices = prices.copy()\n",
    "    prices = prices.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    if use_log:\n",
    "        rets = np.log(prices).diff()\n",
    "    else:\n",
    "        rets = prices.pct_change()\n",
    "\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan)\n",
    "    rets = rets.dropna(how=\"all\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- VaR / ES -----------------------------\n",
    "def rolling_historical_var_es(r: pd.Series, window: int, alpha: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rolling historical VaR and ES on returns series r.\n",
    "    Convention:\n",
    "      - VaR is the alpha-quantile return (typically negative).\n",
    "      - ES is average return <= VaR (also negative).\n",
    "    \"\"\"\n",
    "    r = r.dropna()\n",
    "    n = len(r)\n",
    "\n",
    "    var_arr = np.full(n, np.nan, dtype=float)\n",
    "    es_arr = np.full(n, np.nan, dtype=float)\n",
    "\n",
    "    vals = r.values\n",
    "    for t in range(window, n):\n",
    "        w = vals[t - window: t]\n",
    "        q = float(np.quantile(w, alpha))\n",
    "        tail = w[w <= q]\n",
    "        var_arr[t] = q\n",
    "        es_arr[t] = float(tail.mean()) if tail.size else np.nan\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\"VaR\": var_arr, \"ES\": es_arr},\n",
    "        index=r.index\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------- Backtests -----------------------------\n",
    "def _safe_log(x: float) -> float:\n",
    "    return math.log(max(x, 1e-15))\n",
    "\n",
    "\n",
    "def kupiec_pof(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Kupiec Proportion of Failures (POF) test.\n",
    "    exceed = 1 if loss exceeded VaR (i.e., return < VaR).\n",
    "    \"\"\"\n",
    "    exceed = exceed.astype(int)\n",
    "    T = int(exceed.size)\n",
    "    x = int(exceed.sum())\n",
    "\n",
    "    # Handle edge cases\n",
    "    if T == 0:\n",
    "        return {\"LR_pof\": float(\"nan\"), \"p_value\": float(\"nan\"), \"T\": 0, \"x\": 0, \"hit_rate\": float(\"nan\")}\n",
    "\n",
    "    phat = x / T\n",
    "    # Likelihood ratio\n",
    "    # LR = -2 [ ln((1-a)^(T-x) a^x) - ln((1-phat)^(T-x) phat^x) ]\n",
    "    ll0 = (T - x) * _safe_log(1 - alpha) + x * _safe_log(alpha)\n",
    "    ll1 = (T - x) * _safe_log(1 - phat) + x * _safe_log(phat)\n",
    "    LR = -2.0 * (ll0 - ll1)\n",
    "\n",
    "    # p-value via chi-square(1) approx using survival function\n",
    "    # We'll implement a simple approx: p = 1 - CDF_chi2(LR, df=1)\n",
    "    p = chi2_sf(LR, df=1)\n",
    "\n",
    "    return {\"LR_pof\": float(LR), \"p_value\": float(p), \"T\": float(T), \"x\": float(x), \"hit_rate\": float(phat)}\n",
    "\n",
    "\n",
    "def christoffersen_independence(exceed: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Christoffersen independence test for exceedances (2-state Markov).\n",
    "    \"\"\"\n",
    "    exceed = exceed.astype(int)\n",
    "    if exceed.size < 2:\n",
    "        return {\"LR_ind\": float(\"nan\"), \"p_value\": float(\"nan\")}\n",
    "\n",
    "    x_prev = exceed[:-1]\n",
    "    x_curr = exceed[1:]\n",
    "\n",
    "    n00 = int(((x_prev == 0) & (x_curr == 0)).sum())\n",
    "    n01 = int(((x_prev == 0) & (x_curr == 1)).sum())\n",
    "    n10 = int(((x_prev == 1) & (x_curr == 0)).sum())\n",
    "    n11 = int(((x_prev == 1) & (x_curr == 1)).sum())\n",
    "\n",
    "    # transition probs\n",
    "    p01 = n01 / max(n00 + n01, 1)\n",
    "    p11 = n11 / max(n10 + n11, 1)\n",
    "    p1  = (n01 + n11) / max(n00 + n01 + n10 + n11, 1)\n",
    "\n",
    "    # log-likelihoods\n",
    "    ll_ind = (\n",
    "        n00 * _safe_log(1 - p01) + n01 * _safe_log(p01) +\n",
    "        n10 * _safe_log(1 - p11) + n11 * _safe_log(p11)\n",
    "    )\n",
    "    ll_iid = (\n",
    "        (n00 + n10) * _safe_log(1 - p1) + (n01 + n11) * _safe_log(p1)\n",
    "    )\n",
    "\n",
    "    LR = -2.0 * (ll_iid - ll_ind)\n",
    "    p = chi2_sf(LR, df=1)\n",
    "\n",
    "    return {\"LR_ind\": float(LR), \"p_value\": float(p), \"n00\": float(n00), \"n01\": float(n01), \"n10\": float(n10), \"n11\": float(n11)}\n",
    "\n",
    "\n",
    "def christoffersen_conditional_coverage(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Conditional coverage = POF + Independence (df=2).\n",
    "    \"\"\"\n",
    "    pof = kupiec_pof(exceed, alpha)\n",
    "    ind = christoffersen_independence(exceed)\n",
    "\n",
    "    if not np.isfinite(pof[\"LR_pof\"]) or not np.isfinite(ind[\"LR_ind\"]):\n",
    "        return {\"LR_cc\": float(\"nan\"), \"p_value\": float(\"nan\")}\n",
    "\n",
    "    LR = float(pof[\"LR_pof\"] + ind[\"LR_ind\"])\n",
    "    p = chi2_sf(LR, df=2)\n",
    "    return {\"LR_cc\": float(LR), \"p_value\": float(p)}\n",
    "\n",
    "\n",
    "# ----------------------------- Chi-square survival function (no scipy) -----------------------------\n",
    "def chi2_sf(x: float, df: int) -> float:\n",
    "    \"\"\"\n",
    "    Survival function for chi-square with integer df using incomplete gamma approximation.\n",
    "    df=1,2 are most common here.\n",
    "    For df=1: chi-square is distribution of Z^2.\n",
    "    We'll use simple approximations:\n",
    "      - df=1: sf = erfc(sqrt(x/2))\n",
    "      - df=2: sf = exp(-x/2)\n",
    "      - fallback: exp(-x/2) (rough)\n",
    "    \"\"\"\n",
    "    if x < 0 or not np.isfinite(x):\n",
    "        return float(\"nan\")\n",
    "    if df == 1:\n",
    "        return float(math.erfc(math.sqrt(x / 2.0)))\n",
    "    if df == 2:\n",
    "        return float(math.exp(-x / 2.0))\n",
    "    return float(math.exp(-x / 2.0))\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "\n",
    "    rets = compute_returns(prices, cfg.use_log_returns)\n",
    "    if cfg.dropna:\n",
    "        rets = rets.dropna(how=\"any\")\n",
    "\n",
    "    if rets.empty or len(rets) < cfg.window + 50:\n",
    "        raise RuntimeError(f\"Not enough data after cleaning. rows={len(rets)} window={cfg.window}\")\n",
    "\n",
    "    # weights\n",
    "    n = rets.shape[1]\n",
    "    if cfg.weights is None:\n",
    "        w = np.ones(n) / n\n",
    "    else:\n",
    "        if len(cfg.weights) != n:\n",
    "            raise RuntimeError(f\"--weights length {len(cfg.weights)} must match symbols length {n}\")\n",
    "        w = np.array(cfg.weights, dtype=float)\n",
    "        s = w.sum()\n",
    "        if s == 0 or not np.isfinite(s):\n",
    "            raise RuntimeError(\"Weights sum to 0 or invalid.\")\n",
    "        w = w / s\n",
    "\n",
    "    port = (rets.values @ w)\n",
    "    port = pd.Series(port, index=rets.index, name=\"port_ret\")\n",
    "\n",
    "    # rolling VaR/ES\n",
    "    var_es = rolling_historical_var_es(port, window=cfg.window, alpha=cfg.alpha)\n",
    "\n",
    "    df = pd.concat([port, var_es], axis=1).dropna()\n",
    "    # exceedance definition: return < VaR (VaR is alpha-quantile)\n",
    "    exceed = (df[\"port_ret\"].values < df[\"VaR\"].values).astype(int)\n",
    "\n",
    "    # tests\n",
    "    pof = kupiec_pof(exceed, cfg.alpha)\n",
    "    ind = christoffersen_independence(exceed)\n",
    "    cc  = christoffersen_conditional_coverage(exceed, cfg.alpha)\n",
    "\n",
    "    # simple performance stats\n",
    "    ann_ret = float(df[\"port_ret\"].mean() * 252.0)\n",
    "    ann_vol = float(df[\"port_ret\"].std(ddof=1) * math.sqrt(252.0))\n",
    "    sharpe = float(ann_ret / ann_vol) if ann_vol > 0 else float(\"nan\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(df.index.min().date()),\n",
    "            \"end\": str(df.index.max().date()),\n",
    "            \"n_obs\": int(len(df)),\n",
    "            \"window\": int(cfg.window),\n",
    "        },\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": list(cfg.symbols),\n",
    "            \"weights\": [float(x) for x in w],\n",
    "            \"ann_ret\": ann_ret,\n",
    "            \"ann_vol\": ann_vol,\n",
    "            \"sharpe\": sharpe,\n",
    "        },\n",
    "        \"backtests\": {\n",
    "            \"kupiec_pof\": pof,\n",
    "            \"christoffersen_independence\": ind,\n",
    "            \"christoffersen_conditional_coverage\": cc,\n",
    "        },\n",
    "        \"notes\": [\n",
    "            \"Exceedance is defined as return < VaR(alpha) where VaR is rolling historical alpha-quantile.\",\n",
    "            \"p-values are chi-square approximations with df=1 (POF, IND) and df=2 (CC).\",\n",
    "            \"If p-value is small (<0.05), model may fail that test.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"exceed\"] = exceed\n",
    "    return {\"series\": out, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    series: pd.DataFrame = result[\"series\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]        # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    series.to_csv(cfg.out_csv, index=True)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    bt = summary[\"backtests\"]\n",
    "    print(\n",
    "        f\"[BT] Kupiec POF: LR={bt['kupiec_pof']['LR_pof']:.3f}, p={bt['kupiec_pof']['p_value']:.4f}, \"\n",
    "        f\"hit_rate={bt['kupiec_pof']['hit_rate']:.4f} (target={cfg.alpha})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[BT] Christoffersen IND: LR={bt['christoffersen_independence']['LR_ind']:.3f}, \"\n",
    "        f\"p={bt['christoffersen_independence']['p_value']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[BT] Christoffersen CC: LR={bt['christoffersen_conditional_coverage']['LR_cc']:.3f}, \"\n",
    "        f\"p={bt['christoffersen_conditional_coverage']['p_value']:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-95: Rolling Historical VaR/ES + Kupiec/Christoffersen backtests\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--window\", type=int, default=Config.window)\n",
    "\n",
    "    p.add_argument(\"--simple-returns\", action=\"store_true\")\n",
    "    p.add_argument(\"--no-dropna\", action=\"store_true\")\n",
    "\n",
    "    p.add_argument(\"--weights\", nargs=\"+\", type=float, default=None)\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "\n",
    "    weights = tuple(a.weights) if a.weights is not None else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        alpha=float(a.alpha),\n",
    "        window=int(a.window),\n",
    "        use_log_returns=(not a.simple_returns),\n",
    "        dropna=(not a.no_dropna),\n",
    "        weights=weights,\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[OK] Saved series → level95_var_es_series.csv\n",
      "[OK] Saved summary → level95_var_es_backtest_summary.json\n",
      "[BT] Kupiec POF: LR=0.115, p=0.7348, hit_rate=0.0487 (target=0.05)\n",
      "[BT] Christoffersen IND: LR=11.300, p=0.0008\n",
      "[BT] Christoffersen CC: LR=11.415, p=0.0033\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

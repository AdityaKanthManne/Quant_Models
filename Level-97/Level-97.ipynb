{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T19:48:13.963860Z",
     "start_time": "2025-12-28T19:48:11.538152Z"
    }
   },
   "source": [
    "# level97_var_es_backtesting.py\n",
    "# Level-97: VaR Backtesting (Kupiec + Christoffersen) and ES Backtest (simple robust score)\n",
    "#\n",
    "# Outputs:\n",
    "#   - level97_var_backtest_series.csv\n",
    "#   - level97_var_backtest_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level97_var_es_backtesting.py\n",
    "#   python level97_var_es_backtesting.py --symbols SPY QQQ IWM TLT GLD --weights 0.4 0.25 0.15 0.15 0.05\n",
    "#   python level97_var_es_backtesting.py --alpha 0.01 --window 750 --method hist\n",
    "#   python level97_var_es_backtesting.py --alpha 0.05 --method normal\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # Portfolio\n",
    "    weights: Optional[Tuple[float, ...]] = None  # None -> equal weight\n",
    "\n",
    "    # Risk\n",
    "    alpha: float = 0.05\n",
    "    window: int = 756  # ~3 years trading days\n",
    "\n",
    "    # VaR/ES method: \"hist\" or \"normal\"\n",
    "    method: str = \"hist\"\n",
    "\n",
    "    use_log_returns: bool = True\n",
    "    dropna: bool = True\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level97_var_backtest_series.csv\"\n",
    "    out_json: str = \"level97_var_backtest_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _extract_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(f\"No data returned for {symbol}\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        for key in [(\"Adj Close\", symbol), (\"Close\", symbol), (symbol, \"Adj Close\"), (symbol, \"Close\")]:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                if isinstance(s, pd.DataFrame):\n",
    "                    s = s.iloc[:, 0]\n",
    "                s.name = symbol\n",
    "                return s\n",
    "        raise RuntimeError(f\"Could not extract Close/Adj Close for {symbol} from MultiIndex columns.\")\n",
    "\n",
    "    for col in [\"Adj Close\", \"Close\"]:\n",
    "        if col in px.columns:\n",
    "            s = px[col].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "    raise RuntimeError(f\"Missing Close/Adj Close for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    symbols = tuple(symbols)\n",
    "\n",
    "    # batch attempt\n",
    "    try:\n",
    "        px_all = yf.download(list(symbols), start=start, progress=False, group_by=\"column\", auto_adjust=False)\n",
    "        if px_all is not None and not px_all.empty:\n",
    "            series = []\n",
    "            ok = True\n",
    "            for s in symbols:\n",
    "                try:\n",
    "                    series.append(_extract_close_series(px_all, s))\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok and series:\n",
    "                return pd.concat(series, axis=1).sort_index()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback single symbol\n",
    "    series = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, progress=False, auto_adjust=False)\n",
    "        series.append(_extract_close_series(px, s))\n",
    "    return pd.concat(series, axis=1).sort_index()\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame, use_log: bool) -> pd.DataFrame:\n",
    "    prices = prices.replace([np.inf, -np.inf], np.nan)\n",
    "    if use_log:\n",
    "        rets = np.log(prices).diff()\n",
    "    else:\n",
    "        rets = prices.pct_change()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan)\n",
    "    return rets.dropna(how=\"all\")\n",
    "\n",
    "\n",
    "def portfolio_weights(symbols: Tuple[str, ...], weights: Optional[Tuple[float, ...]]) -> np.ndarray:\n",
    "    n = len(symbols)\n",
    "    if weights is None:\n",
    "        return np.ones(n) / n\n",
    "    if len(weights) != n:\n",
    "        raise RuntimeError(f\"--weights length {len(weights)} must match symbols length {n}\")\n",
    "    w = np.array(weights, dtype=float)\n",
    "    s = float(w.sum())\n",
    "    if not np.isfinite(s) or s == 0.0:\n",
    "        raise RuntimeError(\"Weights sum is invalid/zero.\")\n",
    "    return w / s\n",
    "\n",
    "\n",
    "# ----------------------------- Stats helpers (NO SciPy) -----------------------------\n",
    "def _safe_log(x: float) -> float:\n",
    "    return math.log(max(x, 1e-15))\n",
    "\n",
    "\n",
    "def kupiec_pof(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Kupiec (1995) Proportion of Failures test (unconditional coverage).\n",
    "    LR_pof ~ chi2(1) asymptotically. We report LR only (p-value requires chi2 CDF).\n",
    "    \"\"\"\n",
    "    T = int(exceed.size)\n",
    "    x = int(exceed.sum())\n",
    "    phat = x / T if T > 0 else 0.0\n",
    "\n",
    "    # Likelihood ratio\n",
    "    # L0 = (1-a)^(T-x) * a^x\n",
    "    # L1 = (1-phat)^(T-x) * phat^x\n",
    "    # LR = -2 ln(L0/L1)\n",
    "    if x == 0:\n",
    "        # phat=0 -> L1 uses phat^x = 1, (1-phat)^(T) = 1^T = 1\n",
    "        # LR = -2[ (T)*ln(1-a) - 0 ]? actually ln(L0) = T ln(1-a)\n",
    "        lr = -2.0 * (T * _safe_log(1.0 - alpha) - 0.0)\n",
    "    elif x == T:\n",
    "        lr = -2.0 * (T * _safe_log(alpha) - 0.0)\n",
    "    else:\n",
    "        lnL0 = (T - x) * _safe_log(1.0 - alpha) + x * _safe_log(alpha)\n",
    "        lnL1 = (T - x) * _safe_log(1.0 - phat) + x * _safe_log(phat)\n",
    "        lr = -2.0 * (lnL0 - lnL1)\n",
    "\n",
    "    return {\"T\": float(T), \"x\": float(x), \"phat\": float(phat), \"LR_pof\": float(lr)}\n",
    "\n",
    "\n",
    "def christoffersen_ind(exceed: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Christoffersen (1998) Independence test for exceedance clustering.\n",
    "    LR_ind ~ chi2(1) asymptotically.\n",
    "    \"\"\"\n",
    "    e = exceed.astype(int)\n",
    "    if e.size < 2:\n",
    "        return {\"LR_ind\": float(\"nan\"), \"n00\": 0.0, \"n01\": 0.0, \"n10\": 0.0, \"n11\": 0.0}\n",
    "\n",
    "    e0 = e[:-1]\n",
    "    e1 = e[1:]\n",
    "\n",
    "    n00 = int(((e0 == 0) & (e1 == 0)).sum())\n",
    "    n01 = int(((e0 == 0) & (e1 == 1)).sum())\n",
    "    n10 = int(((e0 == 1) & (e1 == 0)).sum())\n",
    "    n11 = int(((e0 == 1) & (e1 == 1)).sum())\n",
    "\n",
    "    # Transition probabilities\n",
    "    pi0 = n01 / (n00 + n01) if (n00 + n01) > 0 else 0.0\n",
    "    pi1 = n11 / (n10 + n11) if (n10 + n11) > 0 else 0.0\n",
    "    pi = (n01 + n11) / (n00 + n01 + n10 + n11) if (n00 + n01 + n10 + n11) > 0 else 0.0\n",
    "\n",
    "    # Log-likelihoods\n",
    "    # L1: Markov\n",
    "    lnL1 = 0.0\n",
    "    lnL1 += n00 * _safe_log(1.0 - pi0) + n01 * _safe_log(pi0)\n",
    "    lnL1 += n10 * _safe_log(1.0 - pi1) + n11 * _safe_log(pi1)\n",
    "\n",
    "    # L0: iid\n",
    "    lnL0 = 0.0\n",
    "    lnL0 += (n00 + n10) * _safe_log(1.0 - pi) + (n01 + n11) * _safe_log(pi)\n",
    "\n",
    "    lr = -2.0 * (lnL0 - lnL1)\n",
    "    return {\n",
    "        \"LR_ind\": float(lr),\n",
    "        \"n00\": float(n00), \"n01\": float(n01), \"n10\": float(n10), \"n11\": float(n11),\n",
    "        \"pi\": float(pi), \"pi0\": float(pi0), \"pi1\": float(pi1)\n",
    "    }\n",
    "\n",
    "\n",
    "def christoffersen_cc(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Conditional Coverage: LR_cc = LR_pof + LR_ind ~ chi2(2)\n",
    "    \"\"\"\n",
    "    pof = kupiec_pof(exceed, alpha)\n",
    "    ind = christoffersen_ind(exceed)\n",
    "    lr_cc = float(pof[\"LR_pof\"] + ind[\"LR_ind\"]) if np.isfinite(ind[\"LR_ind\"]) else float(\"nan\")\n",
    "    return {\"LR_cc\": lr_cc, **{f\"pof_{k}\": v for k, v in pof.items()}, **{f\"ind_{k}\": v for k, v in ind.items()}}\n",
    "\n",
    "\n",
    "def es_backtest_score(returns: np.ndarray, var: np.ndarray, es: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Simple, stable ES backtest score (no SciPy):\n",
    "    - Count VaR exceedances\n",
    "    - Compare realized tail loss vs predicted ES on exceedance days\n",
    "\n",
    "    score = mean( (r - ES_t) | r <= VaR_t )\n",
    "    If ES is calibrated, this should be ~0 (negative means ES too optimistic).\n",
    "    \"\"\"\n",
    "    mask = returns <= var\n",
    "    n = int(mask.sum())\n",
    "    if n == 0:\n",
    "        return {\"n_tail\": 0.0, \"tail_mean_r\": float(\"nan\"), \"tail_mean_es\": float(\"nan\"), \"score\": float(\"nan\")}\n",
    "\n",
    "    tail_r = returns[mask]\n",
    "    tail_es = es[mask]\n",
    "    return {\n",
    "        \"n_tail\": float(n),\n",
    "        \"tail_mean_r\": float(tail_r.mean()),\n",
    "        \"tail_mean_es\": float(tail_es.mean()),\n",
    "        \"score\": float((tail_r - tail_es).mean()),\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Rolling VaR/ES -----------------------------\n",
    "def rolling_hist_var_es(r: np.ndarray, alpha: float, window: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    var = np.full_like(r, np.nan, dtype=float)\n",
    "    es = np.full_like(r, np.nan, dtype=float)\n",
    "\n",
    "    for t in range(window, r.size):\n",
    "        hist = r[t - window:t]\n",
    "        q = float(np.quantile(hist, alpha))\n",
    "        var[t] = q\n",
    "        es[t] = float(hist[hist <= q].mean())\n",
    "    return var, es\n",
    "\n",
    "\n",
    "def rolling_normal_var_es(r: np.ndarray, alpha: float, window: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Parametric Normal VaR/ES with rolling mean/std.\n",
    "    Uses an inverse-CDF approximation for z_alpha to avoid SciPy.\n",
    "    \"\"\"\n",
    "    var = np.full_like(r, np.nan, dtype=float)\n",
    "    es = np.full_like(r, np.nan, dtype=float)\n",
    "\n",
    "    z = inv_norm_cdf(alpha)  # negative number\n",
    "    pdf = (1.0 / math.sqrt(2.0 * math.pi)) * math.exp(-0.5 * z * z)\n",
    "\n",
    "    for t in range(window, r.size):\n",
    "        hist = r[t - window:t]\n",
    "        mu = float(hist.mean())\n",
    "        sig = float(hist.std(ddof=1))\n",
    "        if sig <= 0 or not np.isfinite(sig):\n",
    "            continue\n",
    "        var[t] = mu + sig * z\n",
    "        # ES for normal: mu - sig * pdf / alpha  (for left tail alpha)\n",
    "        es[t] = mu - sig * (pdf / alpha)\n",
    "    return var, es\n",
    "\n",
    "\n",
    "def inv_norm_cdf(p: float) -> float:\n",
    "    \"\"\"\n",
    "    Approx inverse standard normal CDF (Acklam-like rational approximation, scalar).\n",
    "    Good enough for risk backtesting. No SciPy.\n",
    "    \"\"\"\n",
    "    if p <= 0.0 or p >= 1.0:\n",
    "        raise ValueError(\"p must be in (0,1)\")\n",
    "\n",
    "    # Coefficients\n",
    "    a = [-3.969683028665376e+01,  2.209460984245205e+02, -2.759285104469687e+02,\n",
    "          1.383577518672690e+02, -3.066479806614716e+01,  2.506628277459239e+00]\n",
    "    b = [-5.447609879822406e+01,  1.615858368580409e+02, -1.556989798598866e+02,\n",
    "          6.680131188771972e+01, -1.328068155288572e+01]\n",
    "    c = [-7.784894002430293e-03, -3.223964580411365e-01, -2.400758277161838e+00,\n",
    "         -2.549732539343734e+00,  4.374664141464968e+00,  2.938163982698783e+00]\n",
    "    d = [ 7.784695709041462e-03,  3.224671290700398e-01,  2.445134137142996e+00,\n",
    "          3.754408661907416e+00]\n",
    "\n",
    "    plow = 0.02425\n",
    "    phigh = 1 - plow\n",
    "\n",
    "    if p < plow:\n",
    "        q = math.sqrt(-2 * math.log(p))\n",
    "        num = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5])\n",
    "        den = ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
    "        return num / den\n",
    "    if p > phigh:\n",
    "        q = math.sqrt(-2 * math.log(1 - p))\n",
    "        num = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5])\n",
    "        den = ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
    "        return -(num / den)\n",
    "\n",
    "    q = p - 0.5\n",
    "    r = q * q\n",
    "    num = (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5]) * q\n",
    "    den = (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4]) * r + 1)\n",
    "    return num / den\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices, cfg.use_log_returns)\n",
    "    if cfg.dropna:\n",
    "        rets = rets.dropna(how=\"any\")\n",
    "\n",
    "    if rets.empty or len(rets) <= cfg.window + 5:\n",
    "        raise RuntimeError(f\"Not enough data after cleaning. rows={len(rets)} window={cfg.window}\")\n",
    "\n",
    "    w = portfolio_weights(cfg.symbols, cfg.weights)\n",
    "    port = rets.values @ w\n",
    "    idx = rets.index\n",
    "\n",
    "    method = cfg.method.lower().strip()\n",
    "    if method not in (\"hist\", \"normal\"):\n",
    "        raise RuntimeError(\"--method must be 'hist' or 'normal'\")\n",
    "\n",
    "    print(f\"[INFO] Computing rolling {method} VaR/ES: alpha={cfg.alpha} window={cfg.window} ...\")\n",
    "    if method == \"hist\":\n",
    "        var, es = rolling_hist_var_es(port, cfg.alpha, cfg.window)\n",
    "    else:\n",
    "        var, es = rolling_normal_var_es(port, cfg.alpha, cfg.window)\n",
    "\n",
    "    # Backtest region (where var is defined)\n",
    "    valid = np.isfinite(var) & np.isfinite(es)\n",
    "    r_bt = port[valid]\n",
    "    var_bt = var[valid]\n",
    "    es_bt = es[valid]\n",
    "\n",
    "    exceed = (r_bt <= var_bt).astype(int)\n",
    "\n",
    "    pof = kupiec_pof(exceed, cfg.alpha)\n",
    "    ind = christoffersen_ind(exceed)\n",
    "    cc = christoffersen_cc(exceed, cfg.alpha)\n",
    "    es_score = es_backtest_score(r_bt, var_bt, es_bt, cfg.alpha)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"date\": idx,\n",
    "        \"port_ret\": port,\n",
    "        \"VaR\": var,\n",
    "        \"ES\": es,\n",
    "    })\n",
    "    out[\"exceed\"] = ((out[\"port_ret\"] <= out[\"VaR\"]) & np.isfinite(out[\"VaR\"])).astype(int)\n",
    "    out = out.set_index(\"date\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(idx.min().date()),\n",
    "            \"end\": str(idx.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"window\": int(cfg.window),\n",
    "            \"n_backtest\": int(r_bt.size),\n",
    "        },\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": list(cfg.symbols),\n",
    "            \"weights\": [float(x) for x in w],\n",
    "        },\n",
    "        \"var_backtests\": {\n",
    "            \"kupiec_pof\": pof,\n",
    "            \"christoffersen_ind\": ind,\n",
    "            \"christoffersen_cc\": cc,\n",
    "        },\n",
    "        \"es_backtest\": es_score,\n",
    "        \"notes\": [\n",
    "            \"LR statistics are reported without p-values (chi-square CDF would require SciPy).\",\n",
    "            \"Rules of thumb: LR_pof (df=1), LR_ind (df=1), LR_cc (df=2).\",\n",
    "            \"ES score ~ 0 is desirable; negative means ES too optimistic (underestimates tail loss).\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return {\"series\": out, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    series: pd.DataFrame = result[\"series\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]  # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    series.to_csv(cfg.out_csv)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    pof = summary[\"var_backtests\"][\"kupiec_pof\"]\n",
    "    ind = summary[\"var_backtests\"][\"christoffersen_ind\"]\n",
    "    cc = summary[\"var_backtests\"][\"christoffersen_cc\"]\n",
    "    esb = summary[\"es_backtest\"]\n",
    "\n",
    "    print(f\"[OK] Saved series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(\n",
    "        f\"[POF] T={int(pof['T'])} x={int(pof['x'])} phat={pof['phat']:.4f} LR={pof['LR_pof']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[IND] LR={ind['LR_ind']:.3f}  n01={int(ind['n01'])} n11={int(ind['n11'])}  pi0={ind['pi0']:.3f} pi1={ind['pi1']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[CC ] LR={cc['LR_cc']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[ES ] tail_n={int(esb['n_tail'])} score={esb['score']:.6f} (near 0 is good)\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-97: VaR/ES backtesting (Kupiec + Christoffersen)\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "    p.add_argument(\"--weights\", nargs=\"+\", type=float, default=None)\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--window\", type=int, default=Config.window)\n",
    "    p.add_argument(\"--method\", type=str, default=Config.method, choices=[\"hist\", \"normal\"])\n",
    "\n",
    "    p.add_argument(\"--simple-returns\", action=\"store_true\")\n",
    "    p.add_argument(\"--no-dropna\", action=\"store_true\")\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    weights = tuple(a.weights) if a.weights is not None else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        weights=weights,\n",
    "        alpha=float(a.alpha),\n",
    "        window=int(a.window),\n",
    "        method=str(a.method),\n",
    "        use_log_returns=(not a.simple_returns),\n",
    "        dropna=(not a.no_dropna),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Computing rolling hist VaR/ES: alpha=0.05 window=756 ...\n",
      "[OK] Saved series → level97_var_backtest_series.csv\n",
      "[OK] Saved summary → level97_var_backtest_summary.json\n",
      "[POF] T=3264 x=159 phat=0.0487 LR=0.115\n",
      "[IND] LR=11.300  n01=141 n11=18  pi0=0.045 pi1=0.113\n",
      "[CC ] LR=11.415\n",
      "[ES ] tail_n=159 score=0.000146 (near 0 is good)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

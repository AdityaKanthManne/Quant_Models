{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T18:39:17.898413Z",
     "start_time": "2025-12-28T18:39:16.385629Z"
    }
   },
   "source": [
    "# level93_mes_lrmes.py\n",
    "# Level-93: MES / LRMES (Systemic Risk) using free data (yfinance) + EWMA beta\n",
    "#\n",
    "# Computes:\n",
    "#  - Market tail threshold q_m(alpha)\n",
    "#  - MES_i(alpha) = E[r_i | r_m <= q_m(alpha)]\n",
    "#  - EWMA beta(t) for each asset vs market\n",
    "#  - Optional LRMES approximation based on MES (fast, no heavy GARCH)\n",
    "#\n",
    "# Outputs:\n",
    "#  - level93_mes_daily.csv\n",
    "#  - level93_mes_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level93_mes_lrmes.py\n",
    "#   python level93_mes_lrmes.py --market SPY --symbols SPY QQQ IWM EFA EEM TLT LQD GLD --alpha 0.05\n",
    "#   python level93_mes_lrmes.py --alpha 0.01 --lam 0.97 --min_obs 600\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    market: str = \"SPY\"\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    alpha: float = 0.05         # market tail quantile for MES conditioning\n",
    "    lam: float = 0.97           # EWMA decay for beta/cov\n",
    "    use_log_returns: bool = True\n",
    "\n",
    "    min_obs: int = 600          # history needed before emitting time series\n",
    "    clip_u: float = 1e-6        # numerical safety\n",
    "\n",
    "    # LRMES proxy options\n",
    "    compute_lrmes: bool = True\n",
    "    lrmes_horizon_weeks: int = 18   # common horizon used in some approximations\n",
    "    lrmes_cap: float = 0.999        # keep within (0,1)\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level93_mes_daily.csv\"\n",
    "    out_json: str = \"level93_mes_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _extract_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(f\"No data returned for {symbol}\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        candidates = [\n",
    "            (\"Adj Close\", symbol),\n",
    "            (\"Close\", symbol),\n",
    "            (symbol, \"Adj Close\"),\n",
    "            (symbol, \"Close\"),\n",
    "        ]\n",
    "        for key in candidates:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                if isinstance(s, pd.DataFrame):\n",
    "                    s = s.iloc[:, 0]\n",
    "                s.name = symbol\n",
    "                return s\n",
    "\n",
    "        # fallback scan\n",
    "        cols = []\n",
    "        for c in px.columns:\n",
    "            c0 = str(c[0]).lower()\n",
    "            c1 = str(c[1]).lower()\n",
    "            if (symbol.lower() in c0 or symbol.lower() in c1) and (\"close\" in c0 or \"close\" in c1):\n",
    "                cols.append(c)\n",
    "        if cols:\n",
    "            s = px[cols[0]].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "        raise RuntimeError(f\"Could not extract Close/Adj Close for {symbol} from MultiIndex columns.\")\n",
    "\n",
    "    for col in [\"Adj Close\", \"Close\"]:\n",
    "        if col in px.columns:\n",
    "            s = px[col].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "    raise RuntimeError(f\"Missing Close/Adj Close for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    symbols = tuple(symbols)\n",
    "\n",
    "    # batch download first (faster)\n",
    "    try:\n",
    "        px_all = yf.download(list(symbols), start=start, progress=False, group_by=\"column\", auto_adjust=False)\n",
    "        if px_all is not None and not px_all.empty:\n",
    "            ss = []\n",
    "            ok = True\n",
    "            for s in symbols:\n",
    "                try:\n",
    "                    ss.append(_extract_close_series(px_all, s))\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok and ss:\n",
    "                return pd.concat(ss, axis=1).sort_index().dropna(how=\"any\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback per symbol\n",
    "    frames: List[pd.Series] = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, progress=False, auto_adjust=False)\n",
    "        frames.append(_extract_close_series(px, s))\n",
    "    return pd.concat(frames, axis=1).sort_index().dropna(how=\"any\")\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame, use_log: bool) -> pd.DataFrame:\n",
    "    if use_log:\n",
    "        rets = np.log(prices).diff()\n",
    "    else:\n",
    "        rets = prices.pct_change()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    # business-day regularization (helps align)\n",
    "    rets = rets.asfreq(\"B\").dropna()\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- Metrics -----------------------------\n",
    "def ewma_beta_series(rm: np.ndarray, ri: np.ndarray, lam: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    EWMA beta(t) = cov_i,m(t) / var_m(t)\n",
    "    cov update: C = lam*C + (1-lam)*x*y\n",
    "    var update: V = lam*V + (1-lam)*y*y\n",
    "    \"\"\"\n",
    "    T = len(rm)\n",
    "    beta = np.full(T, np.nan)\n",
    "\n",
    "    # initialize with sample moments on first block to avoid long warm-up\n",
    "    C = float(np.cov(ri, rm, ddof=1)[0, 1])\n",
    "    V = float(np.var(rm, ddof=1))\n",
    "    V = max(V, 1e-18)\n",
    "\n",
    "    for t in range(T):\n",
    "        x = float(ri[t])\n",
    "        y = float(rm[t])\n",
    "        C = lam * C + (1.0 - lam) * (x * y)\n",
    "        V = lam * V + (1.0 - lam) * (y * y)\n",
    "        V = max(V, 1e-18)\n",
    "        beta[t] = C / V\n",
    "    return beta\n",
    "\n",
    "\n",
    "def compute_mes(rm: np.ndarray, ri: np.ndarray, alpha: float) -> float:\n",
    "    q = float(np.quantile(rm, alpha))\n",
    "    mask = rm <= q\n",
    "    if mask.sum() < 10:\n",
    "        return float(\"nan\")\n",
    "    return float(np.mean(ri[mask]))\n",
    "\n",
    "\n",
    "def lrmes_proxy_from_mes(mes: float, horizon_weeks: int, cap: float) -> float:\n",
    "    \"\"\"\n",
    "    Fast LRMES proxy (kept bounded).\n",
    "    Note: MES is typically negative in market tail. This proxy maps\n",
    "    more negative MES -> higher LRMES (bigger expected equity loss).\n",
    "    \"\"\"\n",
    "    if not np.isfinite(mes):\n",
    "        return float(\"nan\")\n",
    "    # exponential map; if mes is negative => exp(h*mes) < 1 => LRMES > 0\n",
    "    lr = 1.0 - float(np.exp(horizon_weeks * mes))\n",
    "    lr = float(np.clip(lr, 0.0, cap))\n",
    "    return lr\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    # Ensure market included\n",
    "    all_syms = tuple(dict.fromkeys(list(cfg.symbols) + [cfg.market]))\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {all_syms} from {cfg.start} ...\")\n",
    "    prices = load_prices(all_syms, cfg.start)\n",
    "    rets = compute_returns(prices, cfg.use_log_returns)\n",
    "\n",
    "    # keep only what we need\n",
    "    keep_cols = [c for c in all_syms if c in rets.columns]\n",
    "    rets = rets[keep_cols].dropna(how=\"any\")\n",
    "\n",
    "    if cfg.market not in rets.columns:\n",
    "        raise RuntimeError(f\"Market '{cfg.market}' missing from returns columns.\")\n",
    "\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, assets={rets.shape[1]}\")\n",
    "\n",
    "    if len(rets) < cfg.min_obs:\n",
    "        raise RuntimeError(f\"Not enough return rows ({len(rets)}) for min_obs={cfg.min_obs}\")\n",
    "\n",
    "    rm = rets[cfg.market].values\n",
    "    idx = rets.index\n",
    "\n",
    "    out_rows = []\n",
    "    summary_assets = {}\n",
    "\n",
    "    # static MES (whole sample) for quick ranking\n",
    "    mes_static = {}\n",
    "\n",
    "    for sym in cfg.symbols:\n",
    "        if sym == cfg.market or sym not in rets.columns:\n",
    "            continue\n",
    "        ri = rets[sym].values\n",
    "\n",
    "        # whole-sample MES\n",
    "        mes = compute_mes(rm, ri, cfg.alpha)\n",
    "        mes_static[sym] = mes\n",
    "\n",
    "        # EWMA beta time series\n",
    "        beta = ewma_beta_series(rm, ri, cfg.lam)\n",
    "\n",
    "        # rolling/expanding \"MES\" time series (fast expanding tail conditioning)\n",
    "        # We avoid expensive rolling quantiles by using expanding quantiles every K steps.\n",
    "        # This is the main speed trick.\n",
    "        K = 20  # update tail threshold every 20 days\n",
    "        q_m = np.full(len(rm), np.nan)\n",
    "        for t in range(cfg.min_obs, len(rm)):\n",
    "            if t == cfg.min_obs or (t % K == 0):\n",
    "                q_m[t] = float(np.quantile(rm[:t + 1], cfg.alpha))\n",
    "            else:\n",
    "                q_m[t] = q_m[t - 1]\n",
    "\n",
    "        # daily MES proxy: mean of ri over tail days up to t (expanding)\n",
    "        # Vectorized via cumulative sums of tail mask\n",
    "        tail_mask = rm <= q_m\n",
    "        tail_mask[:cfg.min_obs] = False\n",
    "\n",
    "        tail_counts = np.cumsum(tail_mask.astype(int))\n",
    "        tail_sums = np.cumsum(ri * tail_mask.astype(float))\n",
    "        mes_t = np.full(len(rm), np.nan)\n",
    "        valid = tail_counts > 10\n",
    "        mes_t[valid] = tail_sums[valid] / tail_counts[valid]\n",
    "\n",
    "        if cfg.compute_lrmes:\n",
    "            lrmes_t = np.array([lrmes_proxy_from_mes(m, cfg.lrmes_horizon_weeks, cfg.lrmes_cap) for m in mes_t])\n",
    "        else:\n",
    "            lrmes_t = np.full(len(rm), np.nan)\n",
    "\n",
    "        # store daily outputs (start at min_obs for stability)\n",
    "        for t in range(cfg.min_obs, len(rm)):\n",
    "            out_rows.append({\n",
    "                \"date\": idx[t],\n",
    "                \"symbol\": sym,\n",
    "                \"beta_ewma\": float(beta[t]),\n",
    "                \"MES_expanding\": float(mes_t[t]) if np.isfinite(mes_t[t]) else np.nan,\n",
    "                \"LRMES_proxy\": float(lrmes_t[t]) if np.isfinite(lrmes_t[t]) else np.nan,\n",
    "                \"market_tail_q\": float(q_m[t]) if np.isfinite(q_m[t]) else np.nan,\n",
    "            })\n",
    "\n",
    "        # summary per asset\n",
    "        summary_assets[sym] = {\n",
    "            \"MES_static\": float(mes) if np.isfinite(mes) else None,\n",
    "            \"beta_last\": float(beta[-1]) if np.isfinite(beta[-1]) else None,\n",
    "        }\n",
    "\n",
    "    daily = pd.DataFrame(out_rows).sort_values([\"date\", \"symbol\"])\n",
    "    if daily.empty:\n",
    "        raise RuntimeError(\"No outputs produced. Check symbols/min_obs.\")\n",
    "\n",
    "    # rank by MES_static (more negative => worse in market crashes)\n",
    "    rank = sorted(\n",
    "        [(k, v) for k, v in mes_static.items() if np.isfinite(v)],\n",
    "        key=lambda kv: kv[1]\n",
    "    )\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "        },\n",
    "        \"market\": {\n",
    "            \"symbol\": cfg.market,\n",
    "            \"alpha\": float(cfg.alpha),\n",
    "        },\n",
    "        \"ranking_by_MES_most_negative_first\": [k for k, _ in rank],\n",
    "        \"assets\": summary_assets,\n",
    "    }\n",
    "\n",
    "    return {\"daily\": daily, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    daily: pd.DataFrame = result[\"daily\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]      # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    daily.to_csv(cfg.out_csv, index=False)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved daily → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    # quick last-day snapshot\n",
    "    last_date = daily[\"date\"].max()\n",
    "    snap = daily[daily[\"date\"] == last_date].copy()\n",
    "    snap = snap.sort_values(\"MES_expanding\")\n",
    "    print(f\"[LAST] Date={pd.to_datetime(last_date).date()}  (sorted by MES, worse first)\")\n",
    "    for _, r in snap.head(min(8, len(snap))).iterrows():\n",
    "        print(f\"  {r['symbol']:>5s}  beta={r['beta_ewma']:+.3f}  MES={r['MES_expanding']:+.5f}  LRMES={r['LRMES_proxy']:.3f}\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-93: MES / LRMES (systemic risk) with EWMA beta\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "    p.add_argument(\"--market\", type=str, default=Config.market)\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--lam\", type=float, default=Config.lam)\n",
    "    p.add_argument(\"--min_obs\", type=int, default=Config.min_obs)\n",
    "\n",
    "    p.add_argument(\"--simple-returns\", action=\"store_true\")\n",
    "    p.add_argument(\"--no-lrmes\", action=\"store_true\")\n",
    "    p.add_argument(\"--lrmes-horizon-weeks\", type=int, default=Config.lrmes_horizon_weeks)\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        market=a.market,\n",
    "        start=a.start,\n",
    "        alpha=float(a.alpha),\n",
    "        lam=float(a.lam),\n",
    "        use_log_returns=(not a.simple_returns),\n",
    "        min_obs=int(a.min_obs),\n",
    "        compute_lrmes=(not a.no_lrmes),\n",
    "        lrmes_horizon_weeks=int(a.lrmes_horizon_weeks),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4021 price rows, 4020 return rows, assets=8\n",
      "[OK] Saved daily → level93_mes_daily.csv\n",
      "[OK] Saved summary → level93_mes_summary.json\n",
      "[LAST] Date=2025-12-26  (sorted by MES, worse first)\n",
      "    QQQ  beta=+1.339  MES=-0.03038  LRMES=0.421\n",
      "    IWM  beta=+1.300  MES=-0.02918  LRMES=0.409\n",
      "    EEM  beta=+0.918  MES=-0.02265  LRMES=0.335\n",
      "    EFA  beta=+0.750  MES=-0.02149  LRMES=0.321\n",
      "    LQD  beta=+0.131  MES=-0.00187  LRMES=0.033\n",
      "    GLD  beta=+0.273  MES=+0.00062  LRMES=0.000\n",
      "    TLT  beta=+0.065  MES=+0.00566  LRMES=0.000\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

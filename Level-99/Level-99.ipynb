{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-29T02:28:29.517038Z",
     "start_time": "2025-12-29T02:28:26.163656Z"
    }
   },
   "source": [
    "# level99_evt_pot_gpd_var_es.py\n",
    "# Level-99: EVT POT-GPD Dynamic VaR/ES (Rolling) + Backtesting (SciPy-free)\n",
    "#\n",
    "# Idea:\n",
    "# - Work on portfolio losses L = -r (right tail).\n",
    "# - For each rolling window:\n",
    "#     u = quantile(L, q_u)  (threshold)\n",
    "#     y = L - u | L>u       (exceedances)\n",
    "#     Fit GPD params (xi, beta) via Method-of-Moments (fast, SciPy-free)\n",
    "#     VaR_L(alpha) from POT formula\n",
    "#     ES_L(alpha) from GPD tail mean\n",
    "# - Convert back to returns: VaR_r = -VaR_L, ES_r = -ES_L\n",
    "# - Backtest exceptions r_t <= VaR_t\n",
    "#\n",
    "# Outputs:\n",
    "#   - level99_evt_series.csv\n",
    "#   - level99_evt_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level99_evt_pot_gpd_var_es.py\n",
    "#   python level99_evt_pot_gpd_var_es.py --alpha 0.01 --window 1260 --q_u 0.95 --min-exc 50\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "    weights: Optional[Tuple[float, ...]] = None  # None -> equal-weight\n",
    "\n",
    "    use_log_returns: bool = True\n",
    "    dropna: bool = True\n",
    "\n",
    "    # EVT params\n",
    "    alpha: float = 0.05          # tail prob (on returns left tail; on losses right tail)\n",
    "    window: int = 1000           # rolling window length\n",
    "    q_u: float = 0.90            # threshold quantile for losses (e.g., 0.90 or 0.95)\n",
    "    min_exc: int = 40            # minimum exceedances to fit GPD reliably\n",
    "    xi_clip: Tuple[float, float] = (-0.45, 0.45)  # stabilize MoM\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level99_evt_series.csv\"\n",
    "    out_json: str = \"level99_evt_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _extract_close(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(f\"No data returned for {symbol}\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        for key in [(\"Adj Close\", symbol), (\"Close\", symbol), (symbol, \"Adj Close\"), (symbol, \"Close\")]:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                if isinstance(s, pd.DataFrame):\n",
    "                    s = s.iloc[:, 0]\n",
    "                s.name = symbol\n",
    "                return s\n",
    "        raise RuntimeError(f\"Could not extract Close/Adj Close for {symbol} from MultiIndex columns.\")\n",
    "\n",
    "    for col in [\"Adj Close\", \"Close\"]:\n",
    "        if col in px.columns:\n",
    "            s = px[col].copy()\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                s = s.iloc[:, 0]\n",
    "            s.name = symbol\n",
    "            return s\n",
    "\n",
    "    raise RuntimeError(f\"Missing Close/Adj Close for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    symbols = tuple(symbols)\n",
    "\n",
    "    # Try batch first (faster)\n",
    "    try:\n",
    "        px_all = yf.download(list(symbols), start=start, progress=False, group_by=\"column\", auto_adjust=False)\n",
    "        if px_all is not None and not px_all.empty:\n",
    "            series = []\n",
    "            ok = True\n",
    "            for s in symbols:\n",
    "                try:\n",
    "                    series.append(_extract_close(px_all, s))\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok and series:\n",
    "                return pd.concat(series, axis=1).sort_index()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback single symbol\n",
    "    series = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, progress=False, auto_adjust=False)\n",
    "        series.append(_extract_close(px, s))\n",
    "    return pd.concat(series, axis=1).sort_index()\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame, use_log: bool) -> pd.DataFrame:\n",
    "    prices = prices.replace([np.inf, -np.inf], np.nan)\n",
    "    rets = (np.log(prices).diff() if use_log else prices.pct_change())\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan)\n",
    "    return rets.dropna(how=\"all\")\n",
    "\n",
    "\n",
    "def portfolio_weights(symbols: Tuple[str, ...], weights: Optional[Tuple[float, ...]]) -> np.ndarray:\n",
    "    n = len(symbols)\n",
    "    if weights is None:\n",
    "        return np.ones(n) / n\n",
    "    if len(weights) != n:\n",
    "        raise RuntimeError(f\"--weights length {len(weights)} must match symbols length {n}\")\n",
    "    w = np.array(weights, dtype=float)\n",
    "    s = float(w.sum())\n",
    "    if not np.isfinite(s) or s == 0.0:\n",
    "        raise RuntimeError(\"Weights sum is invalid/zero.\")\n",
    "    return w / s\n",
    "\n",
    "\n",
    "# ----------------------------- Backtest helpers (SciPy-free) -----------------------------\n",
    "def _safe_log(x: float) -> float:\n",
    "    return math.log(max(x, 1e-15))\n",
    "\n",
    "\n",
    "def kupiec_pof(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    T = int(exceed.size)\n",
    "    x = int(exceed.sum())\n",
    "    phat = x / T if T > 0 else 0.0\n",
    "\n",
    "    if x == 0:\n",
    "        lr = -2.0 * (T * _safe_log(1.0 - alpha))\n",
    "    elif x == T:\n",
    "        lr = -2.0 * (T * _safe_log(alpha))\n",
    "    else:\n",
    "        lnL0 = (T - x) * _safe_log(1.0 - alpha) + x * _safe_log(alpha)\n",
    "        lnL1 = (T - x) * _safe_log(1.0 - phat) + x * _safe_log(phat)\n",
    "        lr = -2.0 * (lnL0 - lnL1)\n",
    "\n",
    "    return {\"T\": float(T), \"x\": float(x), \"phat\": float(phat), \"LR_pof\": float(lr)}\n",
    "\n",
    "\n",
    "def christoffersen_ind(exceed: np.ndarray) -> Dict[str, float]:\n",
    "    e = exceed.astype(int)\n",
    "    if e.size < 2:\n",
    "        return {\"LR_ind\": float(\"nan\"), \"n00\": 0.0, \"n01\": 0.0, \"n10\": 0.0, \"n11\": 0.0}\n",
    "\n",
    "    e0, e1 = e[:-1], e[1:]\n",
    "    n00 = int(((e0 == 0) & (e1 == 0)).sum())\n",
    "    n01 = int(((e0 == 0) & (e1 == 1)).sum())\n",
    "    n10 = int(((e0 == 1) & (e1 == 0)).sum())\n",
    "    n11 = int(((e0 == 1) & (e1 == 1)).sum())\n",
    "\n",
    "    pi0 = n01 / (n00 + n01) if (n00 + n01) > 0 else 0.0\n",
    "    pi1 = n11 / (n10 + n11) if (n10 + n11) > 0 else 0.0\n",
    "    pi = (n01 + n11) / (n00 + n01 + n10 + n11) if (n00 + n01 + n10 + n11) > 0 else 0.0\n",
    "\n",
    "    lnL1 = n00 * _safe_log(1 - pi0) + n01 * _safe_log(pi0) + n10 * _safe_log(1 - pi1) + n11 * _safe_log(pi1)\n",
    "    lnL0 = (n00 + n10) * _safe_log(1 - pi) + (n01 + n11) * _safe_log(pi)\n",
    "    lr = -2.0 * (lnL0 - lnL1)\n",
    "\n",
    "    return {\n",
    "        \"LR_ind\": float(lr),\n",
    "        \"n00\": float(n00), \"n01\": float(n01), \"n10\": float(n10), \"n11\": float(n11),\n",
    "        \"pi\": float(pi), \"pi0\": float(pi0), \"pi1\": float(pi1)\n",
    "    }\n",
    "\n",
    "\n",
    "def christoffersen_cc(exceed: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    pof = kupiec_pof(exceed, alpha)\n",
    "    ind = christoffersen_ind(exceed)\n",
    "    lr_cc = float(pof[\"LR_pof\"] + ind[\"LR_ind\"]) if np.isfinite(ind[\"LR_ind\"]) else float(\"nan\")\n",
    "    return {\"LR_cc\": lr_cc, \"pof\": pof, \"ind\": ind}\n",
    "\n",
    "\n",
    "def es_tail_score(r: np.ndarray, var: np.ndarray, es: np.ndarray) -> Dict[str, float]:\n",
    "    mask = r <= var\n",
    "    n = int(mask.sum())\n",
    "    if n == 0:\n",
    "        return {\"n_tail\": 0.0, \"tail_mean_r\": float(\"nan\"), \"tail_mean_es\": float(\"nan\"), \"score\": float(\"nan\")}\n",
    "    tail_r = r[mask]\n",
    "    tail_es = es[mask]\n",
    "    return {\n",
    "        \"n_tail\": float(n),\n",
    "        \"tail_mean_r\": float(tail_r.mean()),\n",
    "        \"tail_mean_es\": float(tail_es.mean()),\n",
    "        \"score\": float((tail_r - tail_es).mean()),\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- EVT: POT-GPD (fast MoM fit) -----------------------------\n",
    "def gpd_mom_fit(y: np.ndarray, xi_clip: Tuple[float, float]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Method-of-moments fit for GPD on exceedances y>0.\n",
    "    mean = beta/(1-xi)  (xi<1)\n",
    "    var  = beta^2/((1-xi)^2*(1-2xi)) (xi<0.5)\n",
    "\n",
    "    => var/mean^2 = 1/(1-2xi)  => xi = 0.5*(1 - mean^2/var)\n",
    "    beta = mean*(1-xi)\n",
    "\n",
    "    This is VERY fast and avoids long optimizers.\n",
    "    \"\"\"\n",
    "    y = y.astype(float)\n",
    "    m = float(y.mean())\n",
    "    v = float(y.var(ddof=1)) if y.size >= 2 else float(y.var())\n",
    "    v = max(v, 1e-12)\n",
    "\n",
    "    xi = 0.5 * (1.0 - (m * m) / v)\n",
    "    xi = float(np.clip(xi, xi_clip[0], xi_clip[1]))\n",
    "\n",
    "    beta = m * (1.0 - xi)\n",
    "    beta = float(max(beta, 1e-12))\n",
    "    return xi, beta\n",
    "\n",
    "\n",
    "def pot_var_es(losses: np.ndarray, alpha: float, q_u: float, min_exc: int, xi_clip: Tuple[float, float]) -> Tuple[float, float, float, int]:\n",
    "    \"\"\"\n",
    "    losses: array of positive-ish losses (right tail is large)\n",
    "    returns:\n",
    "      VaR_loss(alpha), ES_loss(alpha), threshold u, exceedance count k\n",
    "    \"\"\"\n",
    "    L = losses.astype(float)\n",
    "    u = float(np.quantile(L, q_u))\n",
    "    exc = L[L > u] - u\n",
    "    k = int(exc.size)\n",
    "    n = int(L.size)\n",
    "\n",
    "    if k < min_exc or n <= 0:\n",
    "        return float(\"nan\"), float(\"nan\"), u, k\n",
    "\n",
    "    p_u = k / n  # P(L > u)\n",
    "    if alpha >= p_u:\n",
    "        # asking for a tail prob that is not beyond threshold region; POT not appropriate\n",
    "        return float(\"nan\"), float(\"nan\"), u, k\n",
    "\n",
    "    xi, beta = gpd_mom_fit(exc, xi_clip=xi_clip)\n",
    "\n",
    "    # VaR for losses at tail prob alpha: P(L > VaR) = alpha\n",
    "    # P(L > l) = p_u * (1 + xi*(l-u)/beta)^(-1/xi)\n",
    "    # => l = u + (beta/xi)*((alpha/p_u)^(-xi) - 1) , xi!=0\n",
    "    if abs(xi) < 1e-8:\n",
    "        varL = u + beta * math.log(p_u / alpha)\n",
    "    else:\n",
    "        varL = u + (beta / xi) * (((alpha / p_u) ** (-xi)) - 1.0)\n",
    "\n",
    "    # ES for losses at alpha (xi<1):\n",
    "    # yq = varL - u\n",
    "    # ES = varL + (beta + xi*yq)/(1 - xi)\n",
    "    if xi >= 0.999:\n",
    "        esL = float(\"nan\")\n",
    "    else:\n",
    "        yq = varL - u\n",
    "        esL = varL + (beta + xi * yq) / (1.0 - xi)\n",
    "\n",
    "    return float(varL), float(esL), u, k\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices, cfg.use_log_returns)\n",
    "    if cfg.dropna:\n",
    "        rets = rets.dropna(how=\"any\")\n",
    "    if rets.empty:\n",
    "        raise RuntimeError(\"No returns after cleaning.\")\n",
    "\n",
    "    w = portfolio_weights(cfg.symbols, cfg.weights)\n",
    "    port_r = rets.values @ w\n",
    "    idx = rets.index\n",
    "\n",
    "    n = port_r.size\n",
    "    if n <= cfg.window + 5:\n",
    "        raise RuntimeError(f\"Not enough rows for window={cfg.window}. rows={n}\")\n",
    "\n",
    "    print(f\"[INFO] rows={n}, window={cfg.window}, alpha={cfg.alpha}, q_u={cfg.q_u}, min_exc={cfg.min_exc}\")\n",
    "    losses = -port_r  # right tail is big losses\n",
    "\n",
    "    VaR = np.full(n, np.nan, dtype=float)\n",
    "    ES = np.full(n, np.nan, dtype=float)\n",
    "    U = np.full(n, np.nan, dtype=float)\n",
    "    K = np.full(n, np.nan, dtype=float)\n",
    "\n",
    "    # Rolling POT-GPD\n",
    "    for t in range(cfg.window, n):\n",
    "        Lwin = losses[t - cfg.window:t]\n",
    "        varL, esL, u, k = pot_var_es(\n",
    "            losses=Lwin,\n",
    "            alpha=cfg.alpha,\n",
    "            q_u=cfg.q_u,\n",
    "            min_exc=cfg.min_exc,\n",
    "            xi_clip=cfg.xi_clip,\n",
    "        )\n",
    "        # Convert back to returns (left tail)\n",
    "        VaR[t] = -varL if np.isfinite(varL) else np.nan\n",
    "        ES[t] = -esL if np.isfinite(esL) else np.nan\n",
    "        U[t] = u\n",
    "        K[t] = k\n",
    "\n",
    "        if (t % 500) == 0:\n",
    "            print(f\"[INFO] t={t}/{n} last_k={k} last_VaR={VaR[t]:.5f}\")\n",
    "\n",
    "    series = pd.DataFrame({\n",
    "        \"date\": idx,\n",
    "        \"port_ret\": port_r,\n",
    "        \"loss\": losses,\n",
    "        \"VaR_evt\": VaR,\n",
    "        \"ES_evt\": ES,\n",
    "        \"u_loss_threshold\": U,\n",
    "        \"n_exceed\": K,\n",
    "    }).set_index(\"date\")\n",
    "\n",
    "    # Backtest where VaR is available\n",
    "    valid = np.isfinite(series[\"VaR_evt\"].values) & np.isfinite(series[\"ES_evt\"].values)\n",
    "    r_bt = series[\"port_ret\"].values[valid]\n",
    "    var_bt = series[\"VaR_evt\"].values[valid]\n",
    "    es_bt = series[\"ES_evt\"].values[valid]\n",
    "\n",
    "    exceed = (r_bt <= var_bt).astype(int)\n",
    "    pof = kupiec_pof(exceed, cfg.alpha)\n",
    "    ind = christoffersen_ind(exceed)\n",
    "    cc = christoffersen_cc(exceed, cfg.alpha)\n",
    "    es_score = es_tail_score(r_bt, var_bt, es_bt)\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\"start\": str(idx.min().date()), \"end\": str(idx.max().date()), \"n_returns\": int(n)},\n",
    "        \"portfolio\": {\"symbols\": list(cfg.symbols), \"weights\": [float(x) for x in w]},\n",
    "        \"availability\": {\n",
    "            \"n_var_points\": int(np.isfinite(VaR).sum()),\n",
    "            \"n_es_points\": int(np.isfinite(ES).sum()),\n",
    "        },\n",
    "        \"backtests\": {\n",
    "            \"kupiec_pof\": pof,\n",
    "            \"christoffersen_ind\": ind,\n",
    "            \"christoffersen_cc\": cc,\n",
    "            \"es_tail_score\": es_score,\n",
    "        },\n",
    "        \"notes\": [\n",
    "            \"EVT POT-GPD models the extreme loss tail; more crisis-sensitive than normal VaR.\",\n",
    "            \"MoM fit is fast and stable, but for very small exceedance samples, results are NaN by design.\",\n",
    "            \"LR statistics reported without p-values (SciPy-free).\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return {\"series\": series, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    series: pd.DataFrame = result[\"series\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]        # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    series.to_csv(cfg.out_csv)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    bt = summary[\"backtests\"]\n",
    "    pof = bt[\"kupiec_pof\"]\n",
    "    ind = bt[\"christoffersen_ind\"]\n",
    "    cc = bt[\"christoffersen_cc\"]\n",
    "    esb = bt[\"es_tail_score\"]\n",
    "\n",
    "    print(f\"[OK] Saved series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(f\"[POF] T={int(pof['T'])} x={int(pof['x'])} phat={pof['phat']:.4f} LR={pof['LR_pof']:.3f}\")\n",
    "    print(f\"[IND] LR={ind['LR_ind']:.3f} n01={int(ind['n01'])} n11={int(ind['n11'])} pi0={ind['pi0']:.3f} pi1={ind['pi1']:.3f}\")\n",
    "    print(f\"[CC ] LR={cc['LR_cc']:.3f}\")\n",
    "    print(f\"[ES ] tail_n={int(esb['n_tail'])} score={esb['score']:.6f} (near 0 is good)\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-99: EVT POT-GPD Dynamic VaR/ES + Backtesting (SciPy-free)\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "    p.add_argument(\"--weights\", nargs=\"+\", type=float, default=None)\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--window\", type=int, default=Config.window)\n",
    "    p.add_argument(\"--q_u\", type=float, default=Config.q_u)\n",
    "    p.add_argument(\"--min-exc\", dest=\"min_exc\", type=int, default=Config.min_exc)\n",
    "\n",
    "    p.add_argument(\"--simple-returns\", action=\"store_true\")\n",
    "    p.add_argument(\"--no-dropna\", action=\"store_true\")\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    weights = tuple(a.weights) if a.weights is not None else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        weights=weights,\n",
    "        alpha=float(a.alpha),\n",
    "        window=int(a.window),\n",
    "        q_u=float(a.q_u),\n",
    "        min_exc=int(a.min_exc),\n",
    "        use_log_returns=(not a.simple_returns),\n",
    "        dropna=(not a.no_dropna),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] rows=4020, window=1000, alpha=0.05, q_u=0.9, min_exc=40\n",
      "[INFO] t=1000/4020 last_k=100 last_VaR=-0.01215\n",
      "[INFO] t=1500/4020 last_k=100 last_VaR=-0.00902\n",
      "[INFO] t=2000/4020 last_k=100 last_VaR=-0.00832\n",
      "[INFO] t=2500/4020 last_k=100 last_VaR=-0.00892\n",
      "[INFO] t=3000/4020 last_k=100 last_VaR=-0.01187\n",
      "[INFO] t=3500/4020 last_k=100 last_VaR=-0.01434\n",
      "[INFO] t=4000/4020 last_k=100 last_VaR=-0.01307\n",
      "[OK] Saved series → level99_evt_series.csv\n",
      "[OK] Saved summary → level99_evt_summary.json\n",
      "[POF] T=3020 x=157 phat=0.0520 LR=0.248\n",
      "[IND] LR=12.086 n01=138 n11=19 pi0=0.048 pi1=0.121\n",
      "[CC ] LR=12.334\n",
      "[ES ] tail_n=157 score=0.000158 (near 0 is good)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
